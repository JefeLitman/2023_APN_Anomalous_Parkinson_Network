{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354e0777",
   "metadata": {},
   "source": [
    "# GANomaly 3D Notebook Black & White training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574169a",
   "metadata": {},
   "source": [
    "## Initial Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b1860",
   "metadata": {},
   "source": [
    "### Model Hiperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '../models/ganomaly_3D/hiperparameters.py'\n",
    "\"\"\"This file contains all the hiperparameters for GANomaly 3D model. You can modify this file in order to change default values stablished here.\n",
    "Version: 1.2\n",
    "Made by: Edgar Rangel\n",
    "\"\"\"\n",
    "\n",
    "def get_options():\n",
    "    \"\"\"This function return a dictionary with the hiperparameters and options to execute the GANomaly 3D model in any of the selected modes. It doesn't require any parameter.\"\"\"\n",
    "\n",
    "    opts = dict(\n",
    "        gpus = '0', # ID of the GPU which will be used\n",
    "        n_cpus = 16, # Number of CPU cores to use while running\n",
    "        lr = 0.0002, # Learning rate\n",
    "        dataset_path = \"../datasets/gait_v2/gait_v2.tfrecord\", # Absolute path where the tfrecord is located to be used\n",
    "        normal_class = 0, # Class label that will be the normal data in the training process\n",
    "        kfolds = 4, # Number of kfolds in which the model will be evaluated with the tfrecord\n",
    "        batch_size = 16, # Input batch size\n",
    "        epochs = 20, # Quantity of epochs to do in training\n",
    "        seed = 8128, # Seed used to enable the replicability of the experiment\n",
    "        save_path = \"../results/Ganomaly_3D/\", # Path where the experiments will be saved\n",
    "        isize = 64, # Input size of the videos, e.g. 64 equals to videos with shape 64x64x64\n",
    "        nc = 1, # Quantity of channels in the data\n",
    "        nz = 100, # Context vector size\n",
    "        ngf = 64, # Quantity of initial filters in the first convolution of the encoder\n",
    "        extra_layers = 0, # Quantity of layer blocks to add before reduction\n",
    "        w_adv = 1, # Adversarial loss weight\n",
    "        w_con = 50, # Contextual loss weight\n",
    "        w_enc = 1, # Encoder loss weight\n",
    "        beta_1 = 0.5, # Momentum of beta 1 in adam optimizer for generator and discriminator\n",
    "        beta_2 = 0.999 # Momentum of beta 2 in adam optimizer for generator and discriminator\n",
    "    )\n",
    "\n",
    "    opts[\"w_gen\"] = (opts[\"w_adv\"], opts[\"w_con\"], opts[\"w_enc\"])\n",
    "    \n",
    "    return opts\n",
    "\n",
    "opts = get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbd460",
   "metadata": {},
   "source": [
    "### Selecting the device to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = opts[\"gpus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6b427",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818e156",
   "metadata": {},
   "source": [
    "### Model functions import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628326d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.gait_v2.extraction_methods import get_data\n",
    "from models.ganomaly_3D.modes.train_eval import exec_loop\n",
    "from models.ganomaly_3D.data_preprocessing import preprocess_gait_dataset\n",
    "from utils.metrics import get_true_positives, get_true_negatives, get_false_positives, get_false_negatives, get_AUC, get_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31005a",
   "metadata": {},
   "source": [
    "### GPU Memory Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") != '-1':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930f45f",
   "metadata": {},
   "source": [
    "## Dataset pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d76530",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = get_data(opts[\"dataset_path\"], opts[\"n_cpus\"])\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536874ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_videos = []\n",
    "labels_videos = []\n",
    "patients_ids = []\n",
    "for x, y, z in total_data:\n",
    "    shape_videos.append(x.numpy().shape)\n",
    "    labels_videos.append(y.numpy())\n",
    "    patients_ids.append(z.numpy())\n",
    "shape_videos = np.r_[shape_videos]\n",
    "labels_videos = np.r_[labels_videos]\n",
    "patients_ids = np.r_[patients_ids]\n",
    "print(\"Data information about the data\")\n",
    "print(\"Total videos: \", shape_videos.shape[0])\n",
    "print(\"Min value of frames: \", np.min(shape_videos[:,0]))\n",
    "print(\"Max value of frames: \", np.max(shape_videos[:,0]))\n",
    "print(\"Mean value of frames: \", np.mean(shape_videos[:,0]))\n",
    "print(\"Unique ids: \", np.unique(patients_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de29666",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = {i:0 for i in np.unique(labels_videos)}\n",
    "videos_4_pat = {i:0 for i in np.unique(patients_ids)}\n",
    "for i, forma in enumerate(shape_videos):\n",
    "    frames = opts[\"isize\"]\n",
    "    to_sum = np.ceil(forma[0] / frames).astype(np.int64)\n",
    "    videos_4_pat[patients_ids[i]] += to_sum\n",
    "    ns[labels_videos[i]] += to_sum\n",
    "for i in ns:\n",
    "    print(\"Video clips for label {}: {}\".format(i, ns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea945205",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_patients_ids = np.unique(patients_ids[labels_videos == opts['normal_class']])\n",
    "abnormal_patients_ids = np.unique(patients_ids[labels_videos != opts['normal_class']])\n",
    "\n",
    "normal_patients_ids, abnormal_patients_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_patients, abnormal_data = preprocess_gait_dataset(\n",
    "    total_data, \n",
    "    opts,\n",
    "    normal_patients_ids,\n",
    "    abnormal_patients_ids\n",
    ")\n",
    "normal_patients, abnormal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1db72e",
   "metadata": {},
   "source": [
    "## Model pre requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acb266",
   "metadata": {},
   "source": [
    "### Experiments readme template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2cc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_template = \"\"\"This file contains information about the experiment made in this instance.\n",
    "\n",
    "All models saved don't include the optimizer, but this file explains how to train in the same conditions.\n",
    "\n",
    "Basic notation:\n",
    "\n",
    "- {i}_Ganomaly3D-{size}x{size}x{size}x{nc}: Experiment id, name of the model and input dimension of model.\n",
    "- H x W x F, F x H x W x C or H x W x C: Data dimensions used where F are frames, H height, W width and C channels.\n",
    "\n",
    "Experiment settings:\n",
    "- The seed used was {seed} for python random module, numpy random and tf random after the library importations.\n",
    "- The batch size was of {batch}.\n",
    "- The optimizer used in this experiment was Adam for generator and discriminator.\n",
    "- The number of classes in this dataset are 2 (Normal and Parkinson) .\n",
    "- This experiment use the data of gait_v2/dataset_09-jun-2022 tfrecord.\n",
    "- The initial lr was of {lr}.\n",
    "- The beta 1 and beta 2 for adam optimizer was {beta_1} and {beta_2} respectively.\n",
    "- The total epochs made in this experiment was of {epochs}.\n",
    "- The context vector size (nz) was of {nz}.\n",
    "- The # channels in data (nc) was of {nc}.\n",
    "- The initial filters in the first convolution of the encoder was {ngf}.\n",
    "- The quantity of layer blocks to add before reduction was of {extra_layers}.\n",
    "- The weights for adversarial, contextual and encoder error respectively in generator were {w_gen}.\n",
    "\n",
    "Transformations applied to data (following this order):\n",
    "- Resize: We resize the frames of volumes to H x W ({size} x {size}).\n",
    "- Equidistant Oversampling volume: We take {size} frames sampled equidistant of volumes to train and test the data.\n",
    "- Convert: We convert the videos in RGB to Grayscale.\n",
    "- Normalize: We normalize the volume with mean and std of 0.5 for both.\n",
    "- Scale: We scale the data between -1 and 1 using min max scaler to be comparable with generated images.\n",
    "- Randomize: We randomize the order of samples in every epoch.\n",
    "\n",
    "Training process:\n",
    "- The data doesn't have train and test partition but we make the partitions like this:\n",
    "    * ~80% (11 patients) of normal (parkinson) data is used in train for kfold {k}.\n",
    "    * ~20% (3 patients) of normal (parkinson) data is used in test for kfold {k}.\n",
    "    * 100% of abnormal (healthy) data are used in test.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf6245",
   "metadata": {},
   "source": [
    "### Data partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = opts[\"kfolds\"]\n",
    "seed = opts[\"seed\"]\n",
    "\n",
    "# Data partition for train and test with kfold\n",
    "kf = KFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "for train_indexes, test_indexes in kf.split(normal_patients):\n",
    "    print([normal_patients_ids[i] for i in train_indexes], [normal_patients_ids[i] for i in test_indexes])\n",
    "    data = normal_patients[train_indexes[0]]\n",
    "    total_samples = videos_4_pat[normal_patients_ids[train_indexes[0]]]\n",
    "    for i in range(1, len(train_indexes)):\n",
    "        data = data.concatenate(normal_patients[train_indexes[i]])\n",
    "        total_samples += videos_4_pat[normal_patients_ids[train_indexes[i]]]\n",
    "    train_folds.append(data.shuffle(total_samples, reshuffle_each_iteration=True).batch(opts['batch_size']).prefetch(-1))\n",
    "        \n",
    "    data = normal_patients[test_indexes[0]]\n",
    "    total_samples = videos_4_pat[normal_patients_ids[test_indexes[0]]]\n",
    "    for i in range(1, len(test_indexes)):\n",
    "        data = data.concatenate(normal_patients[test_indexes[i]])\n",
    "        total_samples += videos_4_pat[normal_patients_ids[test_indexes[i]]]\n",
    "    data = data.concatenate(abnormal_data)\n",
    "    for i in abnormal_patients_ids:\n",
    "        total_samples += videos_4_pat[i]\n",
    "    test_folds.append(data.shuffle(total_samples, reshuffle_each_iteration=True).batch(opts['batch_size']).prefetch(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f581bb7",
   "metadata": {},
   "source": [
    "### Metrics creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = get_true_positives()\n",
    "TN = get_true_negatives()\n",
    "FP = get_false_positives()\n",
    "FN = get_false_negatives()\n",
    "gen_loss = get_mean()\n",
    "disc_loss = get_mean()\n",
    "AUC = get_AUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b81f1",
   "metadata": {},
   "source": [
    "### Loop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a89f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(opts['kfolds']):\n",
    "    exec_loop(\n",
    "        opts,\n",
    "        readme_template,\n",
    "        k,\n",
    "        TP,\n",
    "        TN,\n",
    "        FP,\n",
    "        FN,\n",
    "        AUC,\n",
    "        gen_loss,\n",
    "        disc_loss,\n",
    "        train_folds[k],\n",
    "        test_folds[k]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
