{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354e0777",
   "metadata": {},
   "source": [
    "# GANomaly 3D Notebook Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574169a",
   "metadata": {},
   "source": [
    "## Initial Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b1860",
   "metadata": {},
   "source": [
    "### Model Hiperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04bf695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '../../models/ganomaly_3D/hiperparameters.py'\n",
    "\"\"\"This file contains all the hiperparameters for GANomaly 3D model. You can modify this file in order to change default values stablished here.\n",
    "Version: 1.5\n",
    "Made by: Edgar Rangel\n",
    "\"\"\"\n",
    "\n",
    "def get_options():\n",
    "    \"\"\"This function return a dictionary with the hiperparameters and options to execute the GANomaly 3D model in any of the selected modes. It doesn't require any parameter.\"\"\"\n",
    "\n",
    "    opts = dict(\n",
    "        gpus = '1', # ID of the GPU which will be used\n",
    "        n_cpus = 16, # Number of CPU cores to use while running\n",
    "        lr = 0.0002, # Learning rate\n",
    "        dataset_path = \"../../datasets/gait_v2/gait_v2.tfrecord\", # Absolute path where the tfrecord is located to be used\n",
    "        normal_class = 1, # Class label that will be the normal data in the training process\n",
    "        kfolds = 5, # Number of kfolds in which the model will be evaluated with the tfrecord\n",
    "        batch_size = 16, # Input batch size\n",
    "        epochs = 20000, # Quantity of epochs to do in training\n",
    "        seed = 8128, # Seed used to enable the replicability of the experiment\n",
    "        save_path = \"../../results/Ganomaly_3D/0004_eval_of_0002/\", # Path where the experiments will be saved\n",
    "        save_frecuency = 1000, # Integer indicating between how many epochs the results and models will be saved\n",
    "        gen_model_path = \"../../results/Ganomaly_3D/\", # Path where the generator model (h5) is allocated and will be loaded to run trained models\n",
    "        disc_model_path = \"../../results/Ganomaly_3D/\", # Path where the discriminator model (h5) is allocated and will be loaded to run trained models\n",
    "        eval_train = True, # If its True, then the loaded model will evaluate train data and test data together.\n",
    "        isize = 64, # Input size of the videos, e.g. 64 equals to videos with shape 64x64x64\n",
    "        nc = 1, # Quantity of channels in the data\n",
    "        nz = 100, # Context vector size\n",
    "        ngf = 64, # Quantity of initial filters in the first convolution of the encoder\n",
    "        extra_layers = 0, # Quantity of layer blocks to add before reduction\n",
    "        w_adv = 1, # Adversarial loss weight\n",
    "        w_con = 50, # Contextual loss weight\n",
    "        w_enc = 1, # Encoder loss weight\n",
    "        beta_1 = 0.5, # Momentum of beta 1 in adam optimizer for generator and discriminator\n",
    "        beta_2 = 0.999, # Momentum of beta 2 in adam optimizer for generator and discriminator\n",
    "        readme = \"\"\"This file contains information about the experiment made in this instance.\n",
    "\n",
    "All models saved don't include the optimizer, but this file explains how to train in the same conditions.\n",
    "\n",
    "Basic notation:\n",
    "\n",
    "- {i}_Ganomaly3D-{size}x{size}x{size}x{nc}: Experiment id, name of the model and input dimension of model.\n",
    "- H x W x F, F x H x W x C or H x W x C: Data dimensions used where F are frames, H height, W width and C channels.\n",
    "\n",
    "Experiment settings:\n",
    "- The seed used was {seed} for python random module, numpy random and tf random after the library importations.\n",
    "- The batch size was of {batch}.\n",
    "- The optimizer used in this experiment was Adam for generator and discriminator.\n",
    "- The number of classes in this dataset are 2 (Normal and Parkinson) .\n",
    "- This experiment use the data of gait_v2/dataset_09-jun-2022 tfrecord.\n",
    "- The initial lr was of {lr}.\n",
    "- The beta 1 and beta 2 for adam optimizer was {beta_1} and {beta_2} respectively.\n",
    "- The total epochs made in this experiment was of {epochs}.\n",
    "- The context vector size (nz) was of {nz}.\n",
    "- The # channels in data (nc) was of {nc}.\n",
    "- The initial filters in the first convolution of the encoder was {ngf}.\n",
    "- The quantity of layer blocks to add before reduction was of {extra_layers}.\n",
    "- The weights for adversarial, contextual and encoder error respectively in generator were {w_gen}.\n",
    "\n",
    "Transformations applied to data (following this order):\n",
    "- Resize: We resize the frames of volumes to H x W ({size} x {size}).\n",
    "- Equidistant Oversampling volume: We take {size} frames sampled equidistant of volumes to train and test the data.\n",
    "- Convert: We convert the videos in RGB to Grayscale.\n",
    "- Normalize: We normalize the volume with mean and std of 0.5 for both.\n",
    "- Scale: We scale the data between -1 and 1 using min max scaler to be comparable with generated images.\n",
    "- Identify: We identify each video per patient with an integer value.\n",
    "- Randomize: We randomize the order of samples in every epoch.\n",
    "\n",
    "Training process:\n",
    "- The data doesn't have train and test partition but we make the partitions like this:\n",
    "    * ~80% (11 patients) of normal (parkinson) data is used in train for kfold {k}.\n",
    "    * ~20% (3 patients) of normal (parkinson) data is used in test for kfold {k}.\n",
    "    * ~20% (3 patients) of abnormal (healthy) data are used in test for kfold {k}.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    opts[\"w_gen\"] = (opts[\"w_adv\"], opts[\"w_con\"], opts[\"w_enc\"])\n",
    "    \n",
    "    return opts\n",
    "\n",
    "opts = get_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbd460",
   "metadata": {},
   "source": [
    "### Selecting the device to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7790008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = opts[\"gpus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6b427",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e11a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:32:29.532048: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818e156",
   "metadata": {},
   "source": [
    "### Model functions import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628326d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.gait_v2.extraction_methods import get_data\n",
    "from models.ganomaly_3D.modes.eval import exec_loop as test\n",
    "from models.ganomaly_3D.data_preprocessing import preprocess_gait_dataset\n",
    "from utils.metrics import get_true_positives, get_true_negatives, get_false_positives, get_false_negatives, get_AUC, get_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31005a",
   "metadata": {},
   "source": [
    "### GPU Memory Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def1f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") != '-1':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930f45f",
   "metadata": {},
   "source": [
    "## Dataset pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d76530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:32:33.946162: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 03:32:34.581387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8099 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:1c:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset element_spec=(TensorSpec(shape=(None, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = get_data(opts[\"dataset_path\"], opts[\"n_cpus\"])\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536874ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information about the data\n",
      "Total videos:  240\n",
      "Min value of frames:  72\n",
      "Max value of frames:  387\n",
      "Mean value of frames:  144.6375\n",
      "Unique ids:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n"
     ]
    }
   ],
   "source": [
    "shape_videos = []\n",
    "labels_videos = []\n",
    "patients_ids = []\n",
    "for x, y, z in total_data:\n",
    "    shape_videos.append(x.numpy().shape)\n",
    "    labels_videos.append(y.numpy())\n",
    "    patients_ids.append(z.numpy())\n",
    "shape_videos = np.r_[shape_videos]\n",
    "labels_videos = np.r_[labels_videos]\n",
    "patients_ids = np.r_[patients_ids]\n",
    "print(\"Data information about the data\")\n",
    "print(\"Total videos: \", shape_videos.shape[0])\n",
    "print(\"Min value of frames: \", np.min(shape_videos[:,0]))\n",
    "print(\"Max value of frames: \", np.max(shape_videos[:,0]))\n",
    "print(\"Mean value of frames: \", np.mean(shape_videos[:,0]))\n",
    "print(\"Unique ids: \", np.unique(patients_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de29666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video clips for label 0: 351\n",
      "Video clips for label 1: 313\n"
     ]
    }
   ],
   "source": [
    "ns = {i:0 for i in np.unique(labels_videos)}\n",
    "videos_4_pat = {i:0 for i in np.unique(patients_ids)}\n",
    "for i, forma in enumerate(shape_videos):\n",
    "    frames = opts[\"isize\"]\n",
    "    to_sum = np.ceil(forma[0] / frames).astype(np.int64)\n",
    "    videos_4_pat[patients_ids[i]] += to_sum\n",
    "    ns[labels_videos[i]] += to_sum\n",
    "for i in ns:\n",
    "    print(\"Video clips for label {}: {}\".format(i, ns[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea945205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 26, 28, 29]),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 23, 24, 25, 27, 30]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_patients_ids = np.unique(patients_ids[labels_videos == opts['normal_class']])\n",
    "abnormal_patients_ids = np.unique(patients_ids[labels_videos != opts['normal_class']])\n",
    "\n",
    "normal_patients_ids, abnormal_patients_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a71746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>],\n",
       " [<CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_patients, abnormal_patients = preprocess_gait_dataset(\n",
    "    total_data, \n",
    "    opts,\n",
    "    normal_patients_ids,\n",
    "    abnormal_patients_ids\n",
    ")\n",
    "normal_patients, abnormal_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1db72e",
   "metadata": {},
   "source": [
    "## Model pre requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf6245",
   "metadata": {},
   "source": [
    "### Data partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9938f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold 1\n",
      "\tNormal train ids: [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 28]\n",
      "\tNormal test ids: [19, 26, 29]\n",
      "Kfold 2\n",
      "\tNormal train ids: [12, 15, 17, 18, 19, 20, 21, 22, 26, 28, 29]\n",
      "\tNormal test ids: [13, 14, 16]\n",
      "Kfold 3\n",
      "\tNormal train ids: [12, 13, 14, 16, 17, 18, 19, 21, 26, 28, 29]\n",
      "\tNormal test ids: [15, 20, 22]\n",
      "Kfold 4\n",
      "\tNormal train ids: [13, 14, 15, 16, 19, 20, 21, 22, 26, 28, 29]\n",
      "\tNormal test ids: [12, 17, 18]\n",
      "Kfold 5\n",
      "\tNormal train ids: [12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 29]\n",
      "\tNormal test ids: [21, 28]\n",
      "Kfold 1\n",
      "\tAbnormal test ids: [8, 9, 25, 30]\n",
      "Kfold 2\n",
      "\tAbnormal test ids: [3, 4, 5]\n",
      "Kfold 3\n",
      "\tAbnormal test ids: [2, 11, 27]\n",
      "Kfold 4\n",
      "\tAbnormal test ids: [6, 7, 23]\n",
      "Kfold 5\n",
      "\tAbnormal test ids: [1, 10, 24]\n"
     ]
    }
   ],
   "source": [
    "kfolds = opts[\"kfolds\"]\n",
    "seed = opts[\"seed\"]\n",
    "kf = KFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "test_totals = [0] * kfolds\n",
    "for k, (train_indexes, test_indexes) in enumerate(kf.split(normal_patients)):\n",
    "    data = normal_patients[train_indexes[0]]\n",
    "    total_samples = videos_4_pat[normal_patients_ids[train_indexes[0]]]\n",
    "    for i in range(1, len(train_indexes)):\n",
    "        data = data.concatenate(normal_patients[train_indexes[i]])\n",
    "        total_samples += videos_4_pat[normal_patients_ids[train_indexes[i]]]\n",
    "    train_folds.append(\n",
    "        data.shuffle(\n",
    "            total_samples, \n",
    "            reshuffle_each_iteration=True\n",
    "        ).batch(\n",
    "            opts['batch_size']\n",
    "        ).prefetch(-1)\n",
    "    )\n",
    "\n",
    "    data = normal_patients[test_indexes[0]]\n",
    "    test_totals[k] += videos_4_pat[normal_patients_ids[test_indexes[0]]]\n",
    "    for i in range(1, len(test_indexes)):\n",
    "        data = data.concatenate(normal_patients[test_indexes[i]])\n",
    "        test_totals[k] += videos_4_pat[normal_patients_ids[test_indexes[i]]]\n",
    "    test_folds.append(data)\n",
    "\n",
    "    print(\"Kfold {}\\n\\tNormal train ids: {}\\n\\tNormal test ids: {}\".format(\n",
    "        k + 1,\n",
    "        [normal_patients_ids[i] for i in train_indexes],\n",
    "        [normal_patients_ids[i] for i in test_indexes]\n",
    "    ))\n",
    "\n",
    "for k , (_, test_indexes) in enumerate(kf.split(abnormal_patients)):\n",
    "    data = abnormal_patients[test_indexes[0]]\n",
    "    test_totals[k] += videos_4_pat[abnormal_patients_ids[test_indexes[0]]]\n",
    "    for i in range(1, len(test_indexes)):\n",
    "        data = data.concatenate(abnormal_patients[test_indexes[i]])\n",
    "        test_totals[k] += videos_4_pat[abnormal_patients_ids[test_indexes[i]]]\n",
    "    test_folds[k] = test_folds[k].concatenate(\n",
    "        data\n",
    "    ).shuffle(\n",
    "        test_totals[k], \n",
    "        reshuffle_each_iteration=True\n",
    "    ).batch(\n",
    "        opts['batch_size']\n",
    "    ).prefetch(-1)\n",
    "\n",
    "    print(\"Kfold {}\\n\\tAbnormal test ids: {}\".format(\n",
    "        k + 1,\n",
    "        [abnormal_patients_ids[i] for i in test_indexes]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f581bb7",
   "metadata": {},
   "source": [
    "### Metrics creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "201fbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = get_true_positives()\n",
    "TN = get_true_negatives()\n",
    "FP = get_false_positives()\n",
    "FN = get_false_negatives()\n",
    "AUC = get_AUC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b81f1",
   "metadata": {},
   "source": [
    "### Loop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68831a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:35:10.553190: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1 of 243\n",
      "2022-08-04 03:35:10.987889: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 4 of 243\n",
      "2022-08-04 03:36:35.835756: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 25 of 243\n",
      "2022-08-04 03:36:35.835976: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 26 of 243\n",
      "2022-08-04 03:36:35.836013: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 27 of 243\n",
      "2022-08-04 03:36:36.492249: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 28 of 243\n",
      "2022-08-04 03:36:36.492314: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 29 of 243\n",
      "2022-08-04 03:36:36.492327: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 30 of 243\n",
      "2022-08-04 03:36:36.641288: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 31 of 243\n",
      "2022-08-04 03:36:36.641369: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 32 of 243\n",
      "2022-08-04 03:38:01.566055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 50 of 243\n",
      "2022-08-04 03:38:01.566222: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 51 of 243\n",
      "2022-08-04 03:38:01.594016: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 52 of 243\n",
      "2022-08-04 03:38:01.594162: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 53 of 243\n",
      "2022-08-04 03:38:01.643048: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 54 of 243\n",
      "2022-08-04 03:38:01.643345: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 55 of 243\n",
      "2022-08-04 03:38:01.892867: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 56 of 243\n",
      "2022-08-04 03:38:01.892957: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 57 of 243\n",
      "2022-08-04 03:38:02.064554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 58 of 243\n",
      "2022-08-04 03:39:24.663870: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 66 of 243\n",
      "2022-08-04 03:39:24.663985: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 67 of 243\n",
      "2022-08-04 03:39:25.001518: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 68 of 243\n",
      "2022-08-04 03:39:25.001862: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 69 of 243\n",
      "2022-08-04 03:39:25.001933: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 70 of 243\n",
      "2022-08-04 03:39:25.232148: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 71 of 243\n",
      "2022-08-04 03:39:25.232448: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 72 of 243\n",
      "2022-08-04 03:39:25.361938: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 73 of 243\n",
      "2022-08-04 03:40:48.662145: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 83 of 243\n",
      "2022-08-04 03:40:48.662222: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 84 of 243\n",
      "2022-08-04 03:40:48.662322: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 85 of 243\n",
      "2022-08-04 03:40:49.094919: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 86 of 243\n",
      "2022-08-04 03:40:49.095009: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 87 of 243\n",
      "2022-08-04 03:40:49.095040: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 88 of 243\n",
      "2022-08-04 03:40:49.276986: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 89 of 243\n",
      "2022-08-04 03:40:49.277074: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 90 of 243\n",
      "2022-08-04 03:40:50.901300: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 243\n",
      "2022-08-04 03:42:15.821555: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 104 of 243\n",
      "2022-08-04 03:42:15.821655: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 105 of 243\n",
      "2022-08-04 03:42:15.821684: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 106 of 243\n",
      "2022-08-04 03:42:16.117766: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 107 of 243\n",
      "2022-08-04 03:42:16.118101: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 108 of 243\n",
      "2022-08-04 03:42:16.118181: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 109 of 243\n",
      "2022-08-04 03:42:16.425103: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 110 of 243\n",
      "2022-08-04 03:42:16.425191: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 111 of 243\n",
      "2022-08-04 03:43:37.830592: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 126 of 243\n",
      "2022-08-04 03:43:37.830922: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 127 of 243\n",
      "2022-08-04 03:43:37.830955: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 128 of 243\n",
      "2022-08-04 03:43:38.232313: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 129 of 243\n",
      "2022-08-04 03:43:38.232399: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 130 of 243\n",
      "2022-08-04 03:43:38.232425: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 131 of 243\n",
      "2022-08-04 03:43:38.543211: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 132 of 243\n",
      "2022-08-04 03:43:38.543309: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 133 of 243\n",
      "2022-08-04 03:45:01.019956: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 150 of 243\n",
      "2022-08-04 03:45:01.020125: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 151 of 243\n",
      "2022-08-04 03:45:01.020145: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 152 of 243\n",
      "2022-08-04 03:45:01.349211: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 153 of 243\n",
      "2022-08-04 03:45:01.349312: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 154 of 243\n",
      "2022-08-04 03:45:01.349342: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 155 of 243\n",
      "2022-08-04 03:45:01.482075: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 156 of 243\n",
      "2022-08-04 03:45:01.482267: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 157 of 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:45:01.730712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 158 of 243\n",
      "2022-08-04 03:46:24.253554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 169 of 243\n",
      "2022-08-04 03:46:24.253640: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 170 of 243\n",
      "2022-08-04 03:46:24.253669: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 171 of 243\n",
      "2022-08-04 03:46:24.898621: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 172 of 243\n",
      "2022-08-04 03:46:24.898811: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 173 of 243\n",
      "2022-08-04 03:46:24.898839: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 174 of 243\n",
      "2022-08-04 03:46:24.898860: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 175 of 243\n",
      "2022-08-04 03:46:24.933096: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 176 of 243\n",
      "2022-08-04 03:47:46.907981: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 194 of 243\n",
      "2022-08-04 03:47:46.908294: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 195 of 243\n",
      "2022-08-04 03:47:46.908324: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 196 of 243\n",
      "2022-08-04 03:47:47.181928: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 197 of 243\n",
      "2022-08-04 03:47:47.182006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 198 of 243\n",
      "2022-08-04 03:47:47.182023: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 199 of 243\n",
      "2022-08-04 03:47:47.476799: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 200 of 243\n",
      "2022-08-04 03:47:47.476921: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 201 of 243\n",
      "2022-08-04 03:49:31.634345: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 212 of 243\n",
      "2022-08-04 03:49:31.634427: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 213 of 243\n",
      "2022-08-04 03:49:31.634448: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 214 of 243\n",
      "2022-08-04 03:49:31.634465: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 215 of 243\n",
      "2022-08-04 03:49:32.610949: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 216 of 243\n",
      "2022-08-04 03:49:32.611152: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 217 of 243\n",
      "2022-08-04 03:49:32.611208: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 218 of 243\n",
      "2022-08-04 03:49:32.611241: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 219 of 243\n",
      "2022-08-04 03:49:32.611350: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 220 of 243\n",
      "2022-08-04 03:49:33.099224: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 221 of 243\n",
      "2022-08-04 03:49:33.099310: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 222 of 243\n",
      "2022-08-04 03:49:35.947772: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2022-08-04 03:49:42.205231: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-08-04 03:49:43.783288: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "/home/jefelitman/APN_Anomalous_Parkinson_Network/notebooks/ganomaly_3D/../../utils/metrics.py:62: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  return tn/(tn+fp)\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.9375\n",
      "Precision: 1.0\n",
      "Recall: 0.9375\n",
      "Specificity: nan\n",
      "F1_Score: 0.967741935483871\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.890625\n",
      "Precision: 1.0\n",
      "Recall: 0.890625\n",
      "Specificity: nan\n",
      "F1_Score: 0.9421487603305785\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.8645833134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.8645833134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.9273743016759777\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.8671875\n",
      "Precision: 1.0\n",
      "Recall: 0.8671875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9288702928870293\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.8541666865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.8541666865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.9213483146067416\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.8500000238418579\n",
      "Precision: 1.0\n",
      "Recall: 0.8500000238418579\n",
      "Specificity: nan\n",
      "F1_Score: 0.918918918918919\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.8295454382896423\n",
      "Precision: 1.0\n",
      "Recall: 0.8295454382896423\n",
      "Specificity: nan\n",
      "F1_Score: 0.906832298136646\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 12\n",
      "Accuracy: 0.8385416865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.8385416865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.9121813031161473\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 13\n",
      "Accuracy: 0.8461538553237915\n",
      "Precision: 1.0\n",
      "Recall: 0.8461538553237915\n",
      "Specificity: nan\n",
      "F1_Score: 0.9166666666666666\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 14\n",
      "Accuracy: 0.8392857313156128\n",
      "Precision: 1.0\n",
      "Recall: 0.8392857313156128\n",
      "Specificity: nan\n",
      "F1_Score: 0.912621359223301\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 15\n",
      "Accuracy: 0.8333333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.8333333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.9090909090909091\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 16\n",
      "Accuracy: 0.8312757015228271\n",
      "Precision: 1.0\n",
      "Recall: 0.8312757015228271\n",
      "Specificity: nan\n",
      "F1_Score: 0.9078651685393259\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:50:33.229316: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1 of 169\n",
      "2022-08-04 03:50:33.229431: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 2 of 169\n",
      "2022-08-04 03:50:33.358348: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 3 of 169\n",
      "2022-08-04 03:52:20.946564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 17 of 169\n",
      "2022-08-04 03:52:20.946788: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 18 of 169\n",
      "2022-08-04 03:52:20.946852: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 19 of 169\n",
      "2022-08-04 03:52:20.946903: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 20 of 169\n",
      "2022-08-04 03:52:21.784349: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 21 of 169\n",
      "2022-08-04 03:52:21.784492: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 22 of 169\n",
      "2022-08-04 03:52:21.784513: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 23 of 169\n",
      "2022-08-04 03:52:21.784526: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 24 of 169\n",
      "2022-08-04 03:52:21.784554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 25 of 169\n",
      "2022-08-04 03:52:21.954903: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 26 of 169\n",
      "2022-08-04 03:52:21.954973: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 27 of 169\n",
      "2022-08-04 03:53:55.023712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 48 of 169\n",
      "2022-08-04 03:53:55.023896: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 49 of 169\n",
      "2022-08-04 03:53:55.023941: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 50 of 169\n",
      "2022-08-04 03:53:55.379537: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 51 of 169\n",
      "2022-08-04 03:53:55.379950: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 52 of 169\n",
      "2022-08-04 03:53:55.380042: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 53 of 169\n",
      "2022-08-04 03:53:55.728267: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 54 of 169\n",
      "2022-08-04 03:53:55.728776: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 55 of 169\n",
      "2022-08-04 03:53:55.728867: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 56 of 169\n",
      "2022-08-04 03:53:57.195060: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 63 of 169\n",
      "2022-08-04 03:54:13.502950: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 71 of 169\n",
      "2022-08-04 03:55:36.613840: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 91 of 169\n",
      "2022-08-04 03:55:36.613940: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 92 of 169\n",
      "2022-08-04 03:55:36.898034: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 93 of 169\n",
      "2022-08-04 03:55:36.898122: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 94 of 169\n",
      "2022-08-04 03:55:37.035398: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 95 of 169\n",
      "2022-08-04 03:55:37.035477: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 96 of 169\n",
      "2022-08-04 03:55:37.295440: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 97 of 169\n",
      "2022-08-04 03:55:37.295526: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 169\n",
      "2022-08-04 03:55:37.472998: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 99 of 169\n",
      "2022-08-04 03:57:38.971663: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 107 of 169\n",
      "2022-08-04 03:57:38.972038: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 108 of 169\n",
      "2022-08-04 03:57:38.972072: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 109 of 169\n",
      "2022-08-04 03:57:38.972101: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 110 of 169\n",
      "2022-08-04 03:57:38.972124: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 111 of 169\n",
      "2022-08-04 03:57:39.971460: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 112 of 169\n",
      "2022-08-04 03:57:39.971554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 113 of 169\n",
      "2022-08-04 03:57:39.972173: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 114 of 169\n",
      "2022-08-04 03:57:39.972207: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 115 of 169\n",
      "2022-08-04 03:57:39.972235: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 116 of 169\n",
      "2022-08-04 03:57:40.857965: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 117 of 169\n",
      "2022-08-04 03:57:40.869837: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 118 of 169\n",
      "2022-08-04 03:59:20.480156: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 147 of 169\n",
      "2022-08-04 03:59:20.480263: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 148 of 169\n",
      "2022-08-04 03:59:20.480291: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 149 of 169\n",
      "2022-08-04 03:59:20.993368: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 150 of 169\n",
      "2022-08-04 03:59:20.993457: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 151 of 169\n",
      "2022-08-04 03:59:20.993486: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 152 of 169\n",
      "2022-08-04 03:59:21.300844: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 153 of 169\n",
      "2022-08-04 03:59:21.300893: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 154 of 169\n",
      "2022-08-04 03:59:21.300902: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 155 of 169\n",
      "2022-08-04 03:59:21.655001: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 156 of 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 03:59:22.851395: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0001_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.4375\n",
      "Precision: 0.5\n",
      "Recall: 0.6666666865348816\n",
      "Specificity: 0.1428571492433548\n",
      "F1_Score: 0.5714285714285714\n",
      "AUC: 0.2460317313671112\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.40625\n",
      "Precision: 0.4444444477558136\n",
      "Recall: 0.75\n",
      "Specificity: 0.0625\n",
      "F1_Score: 0.5581395348837209\n",
      "AUC: 0.404296875\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.3333333432674408\n",
      "Precision: 0.3658536672592163\n",
      "Recall: 0.7142857313156128\n",
      "Specificity: 0.03703703731298447\n",
      "F1_Score: 0.4838709677419355\n",
      "AUC: 0.3342151641845703\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.296875\n",
      "Precision: 0.3396226465702057\n",
      "Recall: 0.6428571343421936\n",
      "Specificity: 0.02777777798473835\n",
      "F1_Score: 0.4444444444444444\n",
      "AUC: 0.3169642984867096\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.3125\n",
      "Precision: 0.35820895433425903\n",
      "Recall: 0.6666666865348816\n",
      "Specificity: 0.022727273404598236\n",
      "F1_Score: 0.46601941747572817\n",
      "AUC: 0.31344693899154663\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.2916666567325592\n",
      "Precision: 0.32499998807907104\n",
      "Recall: 0.6499999761581421\n",
      "Specificity: 0.0357142873108387\n",
      "F1_Score: 0.43333333333333335\n",
      "AUC: 0.31941965222358704\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.2857142984867096\n",
      "Precision: 0.32608696818351746\n",
      "Recall: 0.625\n",
      "Specificity: 0.03125\n",
      "F1_Score: 0.42857142857142855\n",
      "AUC: 0.3072916865348816\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.2734375\n",
      "Precision: 0.3173076808452606\n",
      "Recall: 0.6000000238418579\n",
      "Specificity: 0.027397260069847107\n",
      "F1_Score: 0.41509433962264153\n",
      "AUC: 0.3018679916858673\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.2777777910232544\n",
      "Precision: 0.3162393271923065\n",
      "Recall: 0.6065573692321777\n",
      "Specificity: 0.03614457696676254\n",
      "F1_Score: 0.4157303370786517\n",
      "AUC: 0.31038910150527954\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.26249998807907104\n",
      "Precision: 0.30000001192092896\n",
      "Recall: 0.5909090638160706\n",
      "Specificity: 0.03191489353775978\n",
      "F1_Score: 0.3979591836734694\n",
      "AUC: 0.30834946036338806\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.26035502552986145\n",
      "Precision: 0.29927006363868713\n",
      "Recall: 0.5857142806053162\n",
      "Specificity: 0.03030303120613098\n",
      "F1_Score: 0.3961352657004831\n",
      "AUC: 0.30331891775131226\n",
      " ==============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.875\n",
      "Precision: 1.0\n",
      "Recall: 0.875\n",
      "Specificity: nan\n",
      "F1_Score: 0.9333333333333333\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.8333333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.8333333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.9090909090909091\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "Specificity: nan\n",
      "F1_Score: 0.8571428571428571\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.7250000238418579\n",
      "Precision: 1.0\n",
      "Recall: 0.7250000238418579\n",
      "Specificity: nan\n",
      "F1_Score: 0.8405797101449275\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.6770833134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.6770833134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.8074534161490683\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.7142857313156128\n",
      "Precision: 1.0\n",
      "Recall: 0.7142857313156128\n",
      "Specificity: nan\n",
      "F1_Score: 0.8333333333333334\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.6953125\n",
      "Precision: 1.0\n",
      "Recall: 0.6953125\n",
      "Specificity: nan\n",
      "F1_Score: 0.8202764976958525\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.6944444179534912\n",
      "Precision: 1.0\n",
      "Recall: 0.6944444179534912\n",
      "Specificity: nan\n",
      "F1_Score: 0.819672131147541\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.706250011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.706250011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.8278388278388278\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.7215909361839294\n",
      "Precision: 1.0\n",
      "Recall: 0.7215909361839294\n",
      "Specificity: nan\n",
      "F1_Score: 0.8382838283828383\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 12\n",
      "Accuracy: 0.7395833134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.7395833134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.8502994011976048\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 13\n",
      "Accuracy: 0.745192289352417\n",
      "Precision: 1.0\n",
      "Recall: 0.745192289352417\n",
      "Specificity: nan\n",
      "F1_Score: 0.8539944903581267\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 14\n",
      "Accuracy: 0.7321428656578064\n",
      "Precision: 1.0\n",
      "Recall: 0.7321428656578064\n",
      "Specificity: nan\n",
      "F1_Score: 0.845360824742268\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 15\n",
      "Accuracy: 0.737500011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.737500011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.8489208633093526\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 16\n",
      "Accuracy: 0.737051784992218\n",
      "Precision: 1.0\n",
      "Recall: 0.737051784992218\n",
      "Specificity: nan\n",
      "F1_Score: 0.8486238532110092\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 04:01:10.065377: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 79 of 110\n",
      "2022-08-04 04:01:10.086627: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 80 of 110\n",
      "2022-08-04 04:01:10.362854: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 81 of 110\n",
      "2022-08-04 04:01:10.362979: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 82 of 110\n",
      "2022-08-04 04:01:10.543364: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 83 of 110\n",
      "2022-08-04 04:01:10.543441: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 84 of 110\n",
      "2022-08-04 04:01:10.799013: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 85 of 110\n",
      "2022-08-04 04:01:10.799413: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 86 of 110\n",
      "2022-08-04 04:02:33.704548: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 95 of 110\n",
      "2022-08-04 04:02:33.704651: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 96 of 110\n",
      "2022-08-04 04:02:33.925261: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 97 of 110\n",
      "2022-08-04 04:02:33.925344: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 110\n",
      "2022-08-04 04:02:34.171320: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 99 of 110\n",
      "2022-08-04 04:02:34.171535: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 100 of 110\n",
      "2022-08-04 04:02:34.345450: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 101 of 110\n",
      "2022-08-04 04:02:34.345565: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 102 of 110\n",
      "2022-08-04 04:02:34.981924: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 107 of 110\n",
      "2022-08-04 04:02:35.091579: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.8125\n",
      "Precision: 0.800000011920929\n",
      "Recall: 0.8888888955116272\n",
      "Specificity: 0.7142857313156128\n",
      "F1_Score: 0.8421052631578947\n",
      "AUC: 0.8571428656578064\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0002_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.78125\n",
      "Precision: 0.8095238208770752\n",
      "Recall: 0.8500000238418579\n",
      "Specificity: 0.6666666865348816\n",
      "F1_Score: 0.8292682926829268\n",
      "AUC: 0.793749988079071\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.7291666865348816\n",
      "Precision: 0.7142857313156128\n",
      "Recall: 0.8928571343421936\n",
      "Specificity: 0.5\n",
      "F1_Score: 0.7936507936507936\n",
      "AUC: 0.7249999642372131\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.78125\n",
      "Precision: 0.75\n",
      "Recall: 0.9166666865348816\n",
      "Specificity: 0.6071428656578064\n",
      "F1_Score: 0.825\n",
      "AUC: 0.7941467761993408\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.7875000238418579\n",
      "Precision: 0.75\n",
      "Recall: 0.9333333373069763\n",
      "Specificity: 0.6000000238418579\n",
      "F1_Score: 0.8316831683168316\n",
      "AUC: 0.8190476298332214\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.78125\n",
      "Precision: 0.7352941036224365\n",
      "Recall: 0.9433962106704712\n",
      "Specificity: 0.5813953280448914\n",
      "F1_Score: 0.8264462809917356\n",
      "AUC: 0.8207547068595886\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.7909091114997864\n",
      "Precision: 0.7532467246055603\n",
      "Recall: 0.9354838728904724\n",
      "Specificity: 0.6041666865348816\n",
      "F1_Score: 0.8345323741007195\n",
      "AUC: 0.8192204833030701\n",
      " ==============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.8125\n",
      "Precision: 1.0\n",
      "Recall: 0.8125\n",
      "Specificity: nan\n",
      "F1_Score: 0.896551724137931\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.8125\n",
      "Precision: 1.0\n",
      "Recall: 0.8125\n",
      "Specificity: nan\n",
      "F1_Score: 0.896551724137931\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "Specificity: nan\n",
      "F1_Score: 0.8571428571428571\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "Specificity: nan\n",
      "F1_Score: 0.8571428571428571\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "Specificity: nan\n",
      "F1_Score: 0.8571428571428571\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.7604166865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.7604166865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.863905325443787\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.7857142686843872\n",
      "Precision: 1.0\n",
      "Recall: 0.7857142686843872\n",
      "Specificity: nan\n",
      "F1_Score: 0.88\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.7734375\n",
      "Precision: 1.0\n",
      "Recall: 0.7734375\n",
      "Specificity: nan\n",
      "F1_Score: 0.8722466960352423\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.7777777910232544\n",
      "Precision: 1.0\n",
      "Recall: 0.7777777910232544\n",
      "Specificity: nan\n",
      "F1_Score: 0.875\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.7875000238418579\n",
      "Precision: 1.0\n",
      "Recall: 0.7875000238418579\n",
      "Specificity: nan\n",
      "F1_Score: 0.8811188811188811\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.7840909361839294\n",
      "Precision: 1.0\n",
      "Recall: 0.7840909361839294\n",
      "Specificity: nan\n",
      "F1_Score: 0.8789808917197452\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 12\n",
      "Accuracy: 0.7916666865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.7916666865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.8837209302325582\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 13\n",
      "Accuracy: 0.7980769276618958\n",
      "Precision: 1.0\n",
      "Recall: 0.7980769276618958\n",
      "Specificity: nan\n",
      "F1_Score: 0.8877005347593583\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 14\n",
      "Accuracy: 0.7991071343421936\n",
      "Precision: 1.0\n",
      "Recall: 0.7991071343421936\n",
      "Specificity: nan\n",
      "F1_Score: 0.8883374689826302\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 15\n",
      "Accuracy: 0.7916666865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.7916666865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.8837209302325582\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 16\n",
      "Accuracy: 0.7890625\n",
      "Precision: 1.0\n",
      "Recall: 0.7890625\n",
      "Specificity: nan\n",
      "F1_Score: 0.8820960698689956\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 17\n",
      "Accuracy: 0.7876448035240173\n",
      "Precision: 1.0\n",
      "Recall: 0.7876448035240173\n",
      "Specificity: nan\n",
      "F1_Score: 0.8812095032397408\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 04:05:48.911131: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 71 of 114\n",
      "2022-08-04 04:05:48.911314: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 72 of 114\n",
      "2022-08-04 04:05:49.202302: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 73 of 114\n",
      "2022-08-04 04:05:49.202411: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 74 of 114\n",
      "2022-08-04 04:05:49.202454: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 75 of 114\n",
      "2022-08-04 04:05:49.542038: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 76 of 114\n",
      "2022-08-04 04:05:49.542197: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 77 of 114\n",
      "2022-08-04 04:05:49.542248: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 78 of 114\n",
      "2022-08-04 04:05:49.781938: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 79 of 114\n",
      "2022-08-04 04:05:49.782014: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 80 of 114\n",
      "2022-08-04 04:08:02.510460: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 92 of 114\n",
      "2022-08-04 04:08:02.510635: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 93 of 114\n",
      "2022-08-04 04:08:02.510734: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 94 of 114\n",
      "2022-08-04 04:08:02.813124: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 95 of 114\n",
      "2022-08-04 04:08:02.813216: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 96 of 114\n",
      "2022-08-04 04:08:02.813241: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 97 of 114\n",
      "2022-08-04 04:08:02.941681: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 114\n",
      "2022-08-04 04:08:02.941784: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 99 of 114\n",
      "2022-08-04 04:08:03.481749: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 100 of 114\n",
      "2022-08-04 04:08:03.481807: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 101 of 114\n",
      "2022-08-04 04:08:03.481832: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 102 of 114\n",
      "2022-08-04 04:08:03.752377: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 103 of 114\n",
      "2022-08-04 04:08:03.752466: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 104 of 114\n",
      "2022-08-04 04:08:04.730301: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.4375\n",
      "Precision: 0.5833333134651184\n",
      "Recall: 0.6363636255264282\n",
      "Specificity: 0.0\n",
      "F1_Score: 0.6086956521739131\n",
      "AUC: 0.4545454680919647\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0003_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.4375\n",
      "Precision: 0.5384615659713745\n",
      "Recall: 0.699999988079071\n",
      "Specificity: 0.0\n",
      "F1_Score: 0.6086956521739131\n",
      "AUC: 0.5625\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.5625\n",
      "Precision: 0.6388888955116272\n",
      "Recall: 0.7419354915618896\n",
      "Specificity: 0.23529411852359772\n",
      "F1_Score: 0.6865671641791045\n",
      "AUC: 0.6043643355369568\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.59375\n",
      "Precision: 0.6279069781303406\n",
      "Recall: 0.7297297120094299\n",
      "Specificity: 0.40740740299224854\n",
      "F1_Score: 0.675\n",
      "AUC: 0.6716716885566711\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.6000000238418579\n",
      "Precision: 0.6122449040412903\n",
      "Recall: 0.6976743936538696\n",
      "Specificity: 0.4864864945411682\n",
      "F1_Score: 0.6521739130434783\n",
      "AUC: 0.6687617897987366\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.625\n",
      "Precision: 0.6166666746139526\n",
      "Recall: 0.7400000095367432\n",
      "Specificity: 0.5\n",
      "F1_Score: 0.6727272727272727\n",
      "AUC: 0.7182608842849731\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.6428571343421936\n",
      "Precision: 0.6060606241226196\n",
      "Recall: 0.7407407164573669\n",
      "Specificity: 0.5517241358757019\n",
      "F1_Score: 0.6666666666666666\n",
      "AUC: 0.7308428287506104\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.640350878238678\n",
      "Precision: 0.5970149040222168\n",
      "Recall: 0.7407407164573669\n",
      "Specificity: 0.550000011920929\n",
      "F1_Score: 0.6611570247933884\n",
      "AUC: 0.7239197492599487\n",
      " ==============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.9375\n",
      "Precision: 1.0\n",
      "Recall: 0.9375\n",
      "Specificity: nan\n",
      "F1_Score: 0.967741935483871\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.78125\n",
      "Precision: 1.0\n",
      "Recall: 0.78125\n",
      "Specificity: nan\n",
      "F1_Score: 0.8771929824561403\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "Specificity: nan\n",
      "F1_Score: 0.8571428571428571\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.765625\n",
      "Precision: 1.0\n",
      "Recall: 0.765625\n",
      "Specificity: nan\n",
      "F1_Score: 0.8672566371681416\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.800000011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.800000011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.8888888888888888\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.7708333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.7708333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.8705882352941177\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.7946428656578064\n",
      "Precision: 1.0\n",
      "Recall: 0.7946428656578064\n",
      "Specificity: nan\n",
      "F1_Score: 0.8855721393034826\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.78125\n",
      "Precision: 1.0\n",
      "Recall: 0.78125\n",
      "Specificity: nan\n",
      "F1_Score: 0.8771929824561403\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.7708333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.7708333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.8705882352941177\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.7437499761581421\n",
      "Precision: 1.0\n",
      "Recall: 0.7437499761581421\n",
      "Specificity: nan\n",
      "F1_Score: 0.8530465949820788\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.7556818127632141\n",
      "Precision: 1.0\n",
      "Recall: 0.7556818127632141\n",
      "Specificity: nan\n",
      "F1_Score: 0.86084142394822\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 12\n",
      "Accuracy: 0.7447916865348816\n",
      "Precision: 1.0\n",
      "Recall: 0.7447916865348816\n",
      "Specificity: nan\n",
      "F1_Score: 0.8537313432835821\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 13\n",
      "Accuracy: 0.7596153616905212\n",
      "Precision: 1.0\n",
      "Recall: 0.7596153616905212\n",
      "Specificity: nan\n",
      "F1_Score: 0.8633879781420765\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 14\n",
      "Accuracy: 0.7366071343421936\n",
      "Precision: 1.0\n",
      "Recall: 0.7366071343421936\n",
      "Specificity: nan\n",
      "F1_Score: 0.8483290488431876\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 15\n",
      "Accuracy: 0.737500011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.737500011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.8489208633093526\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 16\n",
      "Accuracy: 0.7366254925727844\n",
      "Precision: 1.0\n",
      "Recall: 0.7366254925727844\n",
      "Specificity: nan\n",
      "F1_Score: 0.8483412322274881\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 04:08:43.539195: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 81 of 149\n",
      "2022-08-04 04:10:07.453577: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 87 of 149\n",
      "2022-08-04 04:10:07.453677: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 88 of 149\n",
      "2022-08-04 04:10:07.453767: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 89 of 149\n",
      "2022-08-04 04:10:07.640512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 90 of 149\n",
      "2022-08-04 04:10:07.640603: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 91 of 149\n",
      "2022-08-04 04:10:07.640680: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 92 of 149\n",
      "2022-08-04 04:10:07.918881: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 93 of 149\n",
      "2022-08-04 04:10:07.919275: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 94 of 149\n",
      "2022-08-04 04:12:07.363125: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 107 of 149\n",
      "2022-08-04 04:12:07.363219: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 108 of 149\n",
      "2022-08-04 04:12:07.363241: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 109 of 149\n",
      "2022-08-04 04:12:07.363614: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 110 of 149\n",
      "2022-08-04 04:12:07.363636: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 111 of 149\n",
      "2022-08-04 04:12:08.232871: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 112 of 149\n",
      "2022-08-04 04:12:08.232954: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 113 of 149\n",
      "2022-08-04 04:12:08.232980: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 114 of 149\n",
      "2022-08-04 04:12:08.233002: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 115 of 149\n",
      "2022-08-04 04:12:08.233020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 116 of 149\n",
      "2022-08-04 04:12:08.233045: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 117 of 149\n",
      "2022-08-04 04:12:09.031655: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 118 of 149\n",
      "2022-08-04 04:12:13.070018: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.5\n",
      "Precision: 0.38461539149284363\n",
      "Recall: 1.0\n",
      "Specificity: 0.27272728085517883\n",
      "F1_Score: 0.5555555555555556\n",
      "AUC: 0.6545454263687134\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0004_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.625\n",
      "Precision: 0.550000011920929\n",
      "Recall: 0.7857142686843872\n",
      "Specificity: 0.5\n",
      "F1_Score: 0.6470588235294118\n",
      "AUC: 0.7063491940498352\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.5416666865348816\n",
      "Precision: 0.46875\n",
      "Recall: 0.75\n",
      "Specificity: 0.3928571343421936\n",
      "F1_Score: 0.5769230769230769\n",
      "AUC: 0.683035671710968\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.546875\n",
      "Precision: 0.4651162922382355\n",
      "Recall: 0.7692307829856873\n",
      "Specificity: 0.3947368562221527\n",
      "F1_Score: 0.5797101449275363\n",
      "AUC: 0.7110323905944824\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.550000011920929\n",
      "Precision: 0.49056604504585266\n",
      "Recall: 0.7428571581840515\n",
      "Specificity: 0.4000000059604645\n",
      "F1_Score: 0.5909090909090909\n",
      "AUC: 0.6857143044471741\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.5208333134651184\n",
      "Precision: 0.46875\n",
      "Recall: 0.7142857313156128\n",
      "Specificity: 0.37037035822868347\n",
      "F1_Score: 0.5660377358490566\n",
      "AUC: 0.6490300297737122\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.4910714328289032\n",
      "Precision: 0.4430379867553711\n",
      "Recall: 0.7291666865348816\n",
      "Specificity: 0.3125\n",
      "F1_Score: 0.5511811023622047\n",
      "AUC: 0.6297200322151184\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.4921875\n",
      "Precision: 0.46236559748649597\n",
      "Recall: 0.7413793206214905\n",
      "Specificity: 0.2857142984867096\n",
      "F1_Score: 0.5695364238410596\n",
      "AUC: 0.6189655065536499\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.4930555522441864\n",
      "Precision: 0.48543688654899597\n",
      "Recall: 0.7142857313156128\n",
      "Specificity: 0.28378379344940186\n",
      "F1_Score: 0.5780346820809249\n",
      "AUC: 0.588996171951294\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.48322147130966187\n",
      "Precision: 0.4672897160053253\n",
      "Recall: 0.7142857313156128\n",
      "Specificity: 0.27848100662231445\n",
      "F1_Score: 0.5649717514124294\n",
      "AUC: 0.5835442543029785\n",
      " ==============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.5625\n",
      "Precision: 1.0\n",
      "Recall: 0.5625\n",
      "Specificity: nan\n",
      "F1_Score: 0.72\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/contextual/train/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/encoder/train/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.6875\n",
      "Precision: 1.0\n",
      "Recall: 0.6875\n",
      "Specificity: nan\n",
      "F1_Score: 0.8148148148148148\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.6458333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.6458333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.7848101265822784\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.609375\n",
      "Precision: 1.0\n",
      "Recall: 0.609375\n",
      "Specificity: nan\n",
      "F1_Score: 0.7572815533980582\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.612500011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.612500011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.7596899224806202\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.6145833134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.6145833134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.7612903225806451\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.6160714030265808\n",
      "Precision: 1.0\n",
      "Recall: 0.6160714030265808\n",
      "Specificity: nan\n",
      "F1_Score: 0.7624309392265194\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.6328125\n",
      "Precision: 1.0\n",
      "Recall: 0.6328125\n",
      "Specificity: nan\n",
      "F1_Score: 0.7751196172248804\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 9\n",
      "Accuracy: 0.6458333134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.6458333134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.7848101265822784\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 10\n",
      "Accuracy: 0.643750011920929\n",
      "Precision: 1.0\n",
      "Recall: 0.643750011920929\n",
      "Specificity: nan\n",
      "F1_Score: 0.7832699619771863\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 11\n",
      "Accuracy: 0.6590909361839294\n",
      "Precision: 1.0\n",
      "Recall: 0.6590909361839294\n",
      "Specificity: nan\n",
      "F1_Score: 0.7945205479452054\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 12\n",
      "Accuracy: 0.6614583134651184\n",
      "Precision: 1.0\n",
      "Recall: 0.6614583134651184\n",
      "Specificity: nan\n",
      "F1_Score: 0.7962382445141066\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 13\n",
      "Accuracy: 0.6778846383094788\n",
      "Precision: 1.0\n",
      "Recall: 0.6778846383094788\n",
      "Specificity: nan\n",
      "F1_Score: 0.8080229226361032\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 14\n",
      "Accuracy: 0.6696428656578064\n",
      "Precision: 1.0\n",
      "Recall: 0.6696428656578064\n",
      "Specificity: nan\n",
      "F1_Score: 0.8021390374331551\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 15\n",
      "Accuracy: 0.6833333373069763\n",
      "Precision: 1.0\n",
      "Recall: 0.6833333373069763\n",
      "Specificity: nan\n",
      "F1_Score: 0.8118811881188119\n",
      "AUC: 0.0\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 16\n",
      "Accuracy: 0.6953125\n",
      "Precision: 1.0\n",
      "Recall: 0.6953125\n",
      "Specificity: nan\n",
      "F1_Score: 0.8202764976958525\n",
      "AUC: 0.0\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 04:14:39.571515: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 74 of 122\n",
      "2022-08-04 04:14:39.571678: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 75 of 122\n",
      "2022-08-04 04:14:39.925656: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 76 of 122\n",
      "2022-08-04 04:14:39.927079: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 77 of 122\n",
      "2022-08-04 04:14:39.927108: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 78 of 122\n",
      "2022-08-04 04:14:40.234538: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 79 of 122\n",
      "2022-08-04 04:14:40.234611: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 80 of 122\n",
      "2022-08-04 04:14:40.234847: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 81 of 122\n",
      "2022-08-04 04:14:40.501738: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 82 of 122\n",
      "2022-08-04 04:14:40.501994: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 83 of 122\n",
      "2022-08-04 04:16:38.886019: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 96 of 122\n",
      "2022-08-04 04:16:38.886144: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 97 of 122\n",
      "2022-08-04 04:16:38.886165: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 98 of 122\n",
      "2022-08-04 04:16:38.886183: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 99 of 122\n",
      "2022-08-04 04:16:39.739366: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 100 of 122\n",
      "2022-08-04 04:16:39.739446: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 101 of 122\n",
      "2022-08-04 04:16:39.739486: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 102 of 122\n",
      "2022-08-04 04:16:39.739521: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 103 of 122\n",
      "2022-08-04 04:16:39.980008: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 104 of 122\n",
      "2022-08-04 04:16:39.980092: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 105 of 122\n",
      "2022-08-04 04:16:39.980439: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 106 of 122\n",
      "2022-08-04 04:16:40.953062: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 107 of 122\n",
      "2022-08-04 04:16:42.546473: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 1\n",
      "Accuracy: 0.8125\n",
      "Precision: 1.0\n",
      "Recall: 0.699999988079071\n",
      "Specificity: 1.0\n",
      "F1_Score: 0.8235294117647058\n",
      "AUC: 0.8833333253860474\n",
      " ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/adversarial/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/contextual/test/abnormal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/normal.npy': No such file or directory\n",
      "rm: cannot remove '../../results/Ganomaly_3D/0004_eval_of_0002/0005_Ganomaly3D-64x64x64x1/outputs/errors/encoder/test/abnormal.npy': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Test Step: 2\n",
      "Accuracy: 0.71875\n",
      "Precision: 0.699999988079071\n",
      "Recall: 0.8235294222831726\n",
      "Specificity: 0.6000000238418579\n",
      "F1_Score: 0.7567567567567568\n",
      "AUC: 0.6784313917160034\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 3\n",
      "Accuracy: 0.7083333134651184\n",
      "Precision: 0.6896551847457886\n",
      "Recall: 0.800000011920929\n",
      "Specificity: 0.6086956262588501\n",
      "F1_Score: 0.7407407407407407\n",
      "AUC: 0.6469565033912659\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 4\n",
      "Accuracy: 0.609375\n",
      "Precision: 0.5121951103210449\n",
      "Recall: 0.807692289352417\n",
      "Specificity: 0.4736842215061188\n",
      "F1_Score: 0.6268656716417911\n",
      "AUC: 0.533906877040863\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 5\n",
      "Accuracy: 0.637499988079071\n",
      "Precision: 0.5600000023841858\n",
      "Recall: 0.800000011920929\n",
      "Specificity: 0.5111111402511597\n",
      "F1_Score: 0.6588235294117647\n",
      "AUC: 0.5561904907226562\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 6\n",
      "Accuracy: 0.6145833134651184\n",
      "Precision: 0.5666666626930237\n",
      "Recall: 0.7555555701255798\n",
      "Specificity: 0.4901960790157318\n",
      "F1_Score: 0.6476190476190476\n",
      "AUC: 0.5104575157165527\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 7\n",
      "Accuracy: 0.6160714030265808\n",
      "Precision: 0.5797101259231567\n",
      "Recall: 0.7407407164573669\n",
      "Specificity: 0.5\n",
      "F1_Score: 0.6504065040650406\n",
      "AUC: 0.5272987484931946\n",
      " ==============================\n",
      "Epoch: 1 - Test Step: 8\n",
      "Accuracy: 0.6393442749977112\n",
      "Precision: 0.5890411138534546\n",
      "Recall: 0.7543859481811523\n",
      "Specificity: 0.5384615659713745\n",
      "F1_Score: 0.6615384615384615\n",
      "AUC: 0.5670715570449829\n",
      " ==============================\n"
     ]
    }
   ],
   "source": [
    "load_path = '../../results/Ganomaly_3D/0002_train_parkinson/'\n",
    "for k, folder in enumerate(sorted(os.listdir(load_path))):\n",
    "    opts[\"gen_model_path\"] = os.path.join(load_path, folder, \"gen_model.h5\")\n",
    "    opts[\"disc_model_path\"] = os.path.join(load_path, folder, \"disc_model.h5\")\n",
    "    \n",
    "    test(\n",
    "        opts, \n",
    "        TP,\n",
    "        TN,\n",
    "        FP,\n",
    "        FN,\n",
    "        AUC,\n",
    "        train_folds[k],\n",
    "        test_folds[k]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
