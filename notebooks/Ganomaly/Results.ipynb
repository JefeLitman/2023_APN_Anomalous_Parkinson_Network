{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "endangered-assets",
   "metadata": {},
   "source": [
    "# GANomaly Notebook Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-billy",
   "metadata": {},
   "source": [
    "## Initial Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-meter",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bored-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import shapiroWilks_test, dagostinoPearson_test, bartlett_test, levene_test, fOneWay_test\n",
    "from utils.savers import generate_qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec12b3",
   "metadata": {},
   "source": [
    "### Experiment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5551c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jefelitman/Saved_Models/Anomaly_parkinson/0007_Ganomaly_2D-64x64x64'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = \"0007\"\n",
    "root_path = \"/home/jefelitman/Saved_Models/Anomaly_parkinson/\"\n",
    "for i in sorted(os.listdir(\"/home/jefelitman/Saved_Models/Anomaly_parkinson/\")):\n",
    "    if experiment_id in i:\n",
    "        experiment_folder = os.path.join(root_path, i)\n",
    "experiment_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-audit",
   "metadata": {},
   "source": [
    "## Quantitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-decline",
   "metadata": {},
   "source": [
    "### Metrics loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optimum-genetics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(epoch          9999.000000\n",
       " gen_error        15.544238\n",
       " disc_error        7.823781\n",
       " accuracy          0.930556\n",
       " precision         0.000000\n",
       " recall                 NaN\n",
       " specificity       0.930556\n",
       " f1_score          0.000000\n",
       " auc               0.000000\n",
       " dtype: float64,\n",
       " epoch          0.000000\n",
       " gen_error      1.018160\n",
       " disc_error     0.588961\n",
       " accuracy       0.486111\n",
       " precision      0.000000\n",
       " recall              NaN\n",
       " specificity    0.486111\n",
       " f1_score       0.000000\n",
       " auc            0.000000\n",
       " dtype: float64,\n",
       " array([9.99900000e+03, 1.08318555e+00, 7.71247387e+00, 7.77777791e-01,\n",
       "        0.00000000e+00,            nan, 7.77777791e-01, 0.00000000e+00,\n",
       "        0.00000000e+00]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/train.csv\"))\n",
    "data = train_metrics\n",
    "np.max(data, axis=0), np.min(data, axis=0), data.to_numpy()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-guest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(epoch          9999.000000\n",
       " accuracy          0.932692\n",
       " precision         1.000000\n",
       " recall            0.920455\n",
       " specificity       1.000000\n",
       " f1_score          0.958580\n",
       " auc               1.000000\n",
       " dtype: float64,\n",
       " epoch          0.000000\n",
       " accuracy       0.076923\n",
       " precision      0.214286\n",
       " recall         0.034091\n",
       " specificity    0.312500\n",
       " f1_score       0.058824\n",
       " auc            0.204545\n",
       " dtype: float64,\n",
       " array([9.99900000e+03, 5.86538434e-01, 1.00000000e+00, 5.11363626e-01,\n",
       "        1.00000000e+00, 6.76691729e-01, 1.00000000e+00]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/test.csv\"))\n",
    "data = test_metrics\n",
    "np.max(data, axis=0), np.min(data, axis=0), data.to_numpy()[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-columbia",
   "metadata": {},
   "source": [
    "### Train Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "completed-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(experiment_folder, \"outputs/graphics/quantitative/\")\n",
    "portions = 500\n",
    "rows = 5\n",
    "columns = 4\n",
    "for metric in [\"gen_error\", \"disc_error\", \"accuracy\", \"specificity\"]:\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(30, 25))\n",
    "    fig.suptitle('{} over Epochs'.format(metric))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            axs[i, j].plot(train_metrics[metric][(i*columns+j)*portions:(i*columns+j+1)*portions])\n",
    "            filename = 'train_{}.png'.format(metric)\n",
    "    fig.savefig(path+filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-giant",
   "metadata": {},
   "source": [
    "### Test graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "least-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(experiment_folder, \"outputs/graphics/quantitative/\")\n",
    "portions = 500\n",
    "rows = 5\n",
    "columns = 4\n",
    "for metric in test_metrics.columns[1:]:\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(30, 25))\n",
    "    fig.suptitle('{} over Epochs'.format(metric))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            axs[i, j].plot(test_metrics[metric][(i*columns+j)*portions:(i*columns+j+1)*portions])\n",
    "            filename = 'test_{}.png'.format(metric)\n",
    "    fig.savefig(path+filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-recipient",
   "metadata": {},
   "source": [
    "## Qualitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-handy",
   "metadata": {},
   "source": [
    "### Errors loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "configured-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/errors/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for m in [\"train\", \"test\"]:\n",
    "        classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            all_data = \"all_{}_{}\".format(t, c)\n",
    "            if all_data not in globals().keys():\n",
    "                globals()[all_data] = np.r_[[]]\n",
    "            \n",
    "            errors = np.load(os.path.join(base_path, t, m, c+\".npy\"))\n",
    "            globals()[\"{}_{}_{}\".format(m, t, c)] = errors\n",
    "            globals()[all_data] = np.concatenate([globals()[all_data], errors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-remains",
   "metadata": {},
   "source": [
    "### Train means and stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "disciplinary-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder error (normal): 0.0025080834901826973 +- 0.0014001932501587794\n",
      "\n",
      "contextual error (normal): 0.0206514958343986 +- 0.0030040974182617957\n",
      "\n",
      "adversarial error (normal): 0.043870693202027015 +- 0.013637413307293152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\"]:\n",
    "        data = globals()[\"train_{}_{}\".format(t,c)]\n",
    "        print(\"{i} error ({j}): {m} +- {s}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = np.mean(data),\n",
    "            s = np.std(data)\n",
    "        ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-status",
   "metadata": {},
   "source": [
    "### Train statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continuing-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for encoder (normal): 3.5184963167717445e-06\n",
      "Shapiro-Wilks test for encoder (normal): 2.344929725950351e-06\n",
      "Barlett test for encoder (normal): 3.915935961124386e-183\n",
      "Levene test for encoder (normal): 9.499230984278309e-20\n",
      "F1 test for encoder (normal): 0.07608029703921523\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for contextual (normal): 0.022296212328180826\n",
      "Shapiro-Wilks test for contextual (normal): 0.004684805404394865\n",
      "Barlett test for contextual (normal): 4.6360496877840635e-161\n",
      "Levene test for contextual (normal): 2.732088321897578e-21\n",
      "F1 test for contextual (normal): 0.8729308026138793\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for adversarial (normal): 0.05704069250220148\n",
      "Shapiro-Wilks test for adversarial (normal): 0.004151544999331236\n",
      "Barlett test for adversarial (normal): 4.083236804701351e-111\n",
      "Levene test for adversarial (normal): 7.692045230729024e-20\n",
      "F1 test for adversarial (normal): 0.348228491582685\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\"]:\n",
    "        print(\"-------------------------------------------------\")\n",
    "        data = globals()[\"train_{}_{}\".format(t,c)]\n",
    "        norm_dist = stats.norm.rvs(loc=0, scale=1, size=data.shape)\n",
    "        print(\"D'agostino-Pearson test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = dagostinoPearson_test(data)\n",
    "        ))\n",
    "        print(\"Shapiro-Wilks test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = shapiroWilks_test(data)\n",
    "        ))\n",
    "        print(\"Barlett test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = bartlett_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"Levene test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = levene_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"F1 test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = fOneWay_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"-------------------------------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-indian",
   "metadata": {},
   "source": [
    "### Test means and stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tired-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder error (normal): 0.002167530466977041 +- 0.0008331999687415564\n",
      "encoder error (abnormal): 0.31252001717009326 +- 0.12864213281290274\n",
      "\n",
      "contextual error (normal): 0.02123068564105779 +- 0.0021946933317612237\n",
      "contextual error (abnormal): 0.16488883475011046 +- 0.020543156872943457\n",
      "\n",
      "adversarial error (normal): 0.052566925529390574 +- 0.015829520480799407\n",
      "adversarial error (abnormal): 0.6470565812831576 +- 0.21261434485833536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        data = globals()[\"test_{}_{}\".format(t,c)]\n",
    "        print(\"{i} error ({j}): {m} +- {s}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = np.mean(data),\n",
    "            s = np.std(data)\n",
    "        ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-remove",
   "metadata": {},
   "source": [
    "### Test statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "funny-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for encoder (normal): 0.0012233838688052742\n",
      "Shapiro-Wilks test for encoder (normal): 0.014776092953979969\n",
      "Barlett test for encoder (normal): 9.052215604053039e-43\n",
      "Levene test for encoder (normal): 6.050504954439661e-05\n",
      "F1 test for encoder (normal): 0.1280558186804157\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for encoder (abnormal): 0.004594977283238486\n",
      "Shapiro-Wilks test for encoder (abnormal): 8.364874520339072e-05\n",
      "Barlett test for encoder (abnormal): 8.457663246366759e-51\n",
      "Levene test for encoder (abnormal): 5.630032962350611e-28\n",
      "F1 test for encoder (abnormal): 0.017916308170033913\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for contextual (normal): 0.07247774670604946\n",
      "Shapiro-Wilks test for contextual (normal): 0.03729066997766495\n",
      "Barlett test for contextual (normal): 1.8307618797600964e-37\n",
      "Levene test for contextual (normal): 5.337428475376518e-06\n",
      "F1 test for contextual (normal): 0.3017648320503031\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for contextual (abnormal): 0.0009662841147269445\n",
      "Shapiro-Wilks test for contextual (abnormal): 0.012210533022880554\n",
      "Barlett test for contextual (abnormal): 1.3712588927729273e-122\n",
      "Levene test for contextual (abnormal): 5.198912314971685e-26\n",
      "F1 test for contextual (abnormal): 0.1468400720463162\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for adversarial (normal): 0.01577784935005131\n",
      "Shapiro-Wilks test for adversarial (normal): 0.0019044240470975637\n",
      "Barlett test for adversarial (normal): 2.4889792877740805e-24\n",
      "Levene test for adversarial (normal): 1.0099942921133818e-05\n",
      "F1 test for adversarial (normal): 0.8773699086306372\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for adversarial (abnormal): 0.22153991023736294\n",
      "Shapiro-Wilks test for adversarial (abnormal): 0.035696495324373245\n",
      "Barlett test for adversarial (abnormal): 3.5338950536711356e-27\n",
      "Levene test for adversarial (abnormal): 8.437081896916784e-16\n",
      "F1 test for adversarial (abnormal): 4.6394878086652086e-08\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:1604: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=16\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        print(\"-------------------------------------------------\")\n",
    "        data = globals()[\"test_{}_{}\".format(t,c)]\n",
    "        norm_dist = stats.norm.rvs(loc=0, scale=1, size=data.shape)\n",
    "        print(\"D'agostino-Pearson test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = dagostinoPearson_test(data)\n",
    "        ))\n",
    "        print(\"Shapiro-Wilks test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = shapiroWilks_test(data)\n",
    "        ))\n",
    "        print(\"Barlett test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = bartlett_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"Levene test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = levene_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"F1 test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = fOneWay_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"-------------------------------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b956fca",
   "metadata": {},
   "source": [
    "### All data means and stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14458150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder error (normal): 0.0024461647586907598 +- 0.0013219508351728952\n",
      "encoder error (abnormal): 0.31252001717009326 +- 0.12864213281290274\n",
      "\n",
      "contextual error (normal): 0.020756803071972998 +- 0.0028826078034521227\n",
      "contextual error (abnormal): 0.16488883475011046 +- 0.020543156872943457\n",
      "\n",
      "adversarial error (normal): 0.04545182635245675 +- 0.014455913931924264\n",
      "adversarial error (abnormal): 0.6470565812831576 +- 0.21261434485833536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        data = globals()[\"all_{}_{}\".format(t,c)]\n",
    "        print(\"{i} error ({j}): {m} +- {s}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = np.mean(data),\n",
    "            s = np.std(data)\n",
    "        ))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8b130",
   "metadata": {},
   "source": [
    "### All data statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bbc99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for encoder (normal): 5.5146320522314296e-08\n",
      "Shapiro-Wilks test for encoder (normal): 1.3985616931222467e-07\n",
      "Barlett test for encoder (normal): 3.1179559469854234e-223\n",
      "Levene test for encoder (normal): 1.7334555115999248e-23\n",
      "F1 test for encoder (normal): 0.18247039029239423\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for encoder (abnormal): 0.004594977283238486\n",
      "Shapiro-Wilks test for encoder (abnormal): 8.364874520339072e-05\n",
      "Barlett test for encoder (abnormal): 2.084687883888159e-56\n",
      "Levene test for encoder (abnormal): 8.463638305752743e-22\n",
      "F1 test for encoder (abnormal): 0.004862282976829902\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for contextual (normal): 0.025634028906761402\n",
      "Shapiro-Wilks test for contextual (normal): 0.005384721327573061\n",
      "Barlett test for contextual (normal): 7.631800789460417e-194\n",
      "Levene test for contextual (normal): 9.301461862164406e-37\n",
      "F1 test for contextual (normal): 0.9258877881145613\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for contextual (abnormal): 0.0009662841147269445\n",
      "Shapiro-Wilks test for contextual (abnormal): 0.012210533022880554\n",
      "Barlett test for contextual (abnormal): 4.267175493576023e-127\n",
      "Levene test for contextual (abnormal): 2.4089833129962588e-29\n",
      "F1 test for contextual (abnormal): 0.48005309970747156\n",
      "-------------------------------------------------\n",
      "\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for adversarial (normal): 0.0253194267425399\n",
      "Shapiro-Wilks test for adversarial (normal): 0.00027297664200887084\n",
      "Barlett test for adversarial (normal): 1.991239268704632e-130\n",
      "Levene test for adversarial (normal): 5.674074868135331e-24\n",
      "F1 test for adversarial (normal): 0.9545178416236745\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "D'agostino-Pearson test for adversarial (abnormal): 0.22153991023736294\n",
      "Shapiro-Wilks test for adversarial (abnormal): 0.035696495324373245\n",
      "Barlett test for adversarial (abnormal): 1.0788002731052379e-35\n",
      "Levene test for adversarial (abnormal): 1.1283321491433731e-14\n",
      "F1 test for adversarial (abnormal): 6.342789157921217e-10\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        print(\"-------------------------------------------------\")\n",
    "        data = globals()[\"all_{}_{}\".format(t,c)]\n",
    "        norm_dist = stats.norm.rvs(loc=0, scale=1, size=data.shape)\n",
    "        print(\"D'agostino-Pearson test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = dagostinoPearson_test(data)\n",
    "        ))\n",
    "        print(\"Shapiro-Wilks test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = shapiroWilks_test(data)\n",
    "        ))\n",
    "        print(\"Barlett test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = bartlett_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"Levene test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = levene_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"F1 test for {i} ({j}): {m}\".format(\n",
    "            i = t,\n",
    "            j = c,\n",
    "            m = fOneWay_test(data, norm_dist)\n",
    "        ))\n",
    "        print(\"-------------------------------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-processor",
   "metadata": {},
   "source": [
    "### Train graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-merchandise",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "motivated-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\"]:\n",
    "        generate_qq_plot(globals()[\"train_{}_{}\".format(t,c)], save_path, \"train_{}_{}\".format(t,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-satin",
   "metadata": {},
   "source": [
    "### Test graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-panic",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "desperate-lease",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(15, 10))\n",
    "for i, t in enumerate([\"encoder\", \"contextual\", \"adversarial\"]):\n",
    "    data = \"test_{}_\".format(t)\n",
    "    axs[i].boxplot([globals()[data+\"normal\"], globals()[data+\"abnormal\"]], labels=['Normal', 'Abnormal'])\n",
    "    axs[i].set_title(\"{} errors\".format(t))\n",
    "\n",
    "filename = 'test_boxplot.png'\n",
    "fig.savefig(save_path+filename)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-multimedia",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "atlantic-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        generate_qq_plot(globals()[\"test_{}_{}\".format(t,c)], save_path, \"test_{}_{}\".format(t,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d353b8",
   "metadata": {},
   "source": [
    "### All data graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d922f",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed03976",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(15, 10))\n",
    "for i, t in enumerate([\"encoder\", \"contextual\", \"adversarial\"]):\n",
    "    data = \"all_{}_\".format(t)\n",
    "    axs[i].boxplot([globals()[data+\"normal\"], globals()[data+\"abnormal\"]], labels=['Normal', 'Abnormal'])\n",
    "    axs[i].set_title(\"{} errors\".format(t))\n",
    "\n",
    "filename = 'all_data_boxplot.png'\n",
    "fig.savefig(save_path+filename)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b27c9",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c433e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        generate_qq_plot(globals()[\"all_{}_{}\".format(t,c)], save_path, \"all_data_{}_{}\".format(t,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-hudson",
   "metadata": {},
   "source": [
    "## Visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-volume",
   "metadata": {},
   "source": [
    "### UMAP latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "yellow-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/latent_vectors/\")\n",
    "for t in [\"in\", \"out\"]:\n",
    "    for m in [\"train\", \"test\"]:\n",
    "        classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            all_data = \"all_{}_{}\".format(t, c)\n",
    "            if all_data not in globals().keys():\n",
    "                globals()[all_data] = []\n",
    "            \n",
    "            data = \"{}_{}_{}\".format(m, t, c)\n",
    "            globals()[data] = []\n",
    "            path = os.path.join(base_path, t, m, c)\n",
    "            for file in sorted(os.listdir(path)):\n",
    "                vector = np.load(os.path.join(path, file))\n",
    "                globals()[data].append(vector)\n",
    "                globals()[all_data].append(vector)\n",
    "            globals()[data] = np.r_[globals()[data]]\n",
    "for t in [\"in\", \"out\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        all_data = \"all_{}_{}\".format(t, c)\n",
    "        globals()[all_data] = np.r_[globals()[all_data]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "apparent-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/visuals/\")\n",
    "for t in [\"in\", \"out\"]:\n",
    "    for m in [\"train\", \"test\", \"all\"]:\n",
    "        classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "        globals()[\"{}_mapped_{}\".format(m, t)] = umap.UMAP(random_state = 8128).fit_transform(np.concatenate(\n",
    "                [globals()[\"{}_{}_{}\".format(m, t, c)] for c in classes], axis=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        divisor = globals()[\"{}_{}_normal\".format(m, t)].shape[0]\n",
    "        plt.scatter(globals()[\"{}_mapped_{}\".format(m, t)][:divisor,0],\n",
    "            globals()[\"{}_mapped_{}\".format(m, t)][:divisor,1], color=\"blue\", s=5, label=\"Normal\"\n",
    "        )\n",
    "        if \"abnormal\" in classes:\n",
    "            plt.scatter(globals()[\"{}_mapped_{}\".format(m, t)][divisor:,0],\n",
    "                globals()[\"{}_mapped_{}\".format(m, t)][divisor:,1], color=\"red\", s=5, label=\"Abnormal\"\n",
    "            )\n",
    "        plt.legend()\n",
    "        plt.title(\"UMAP for {}put data in {}\".format(t, m))\n",
    "        filename = '{}_umap_{}put.png'.format(m, t)\n",
    "        plt.savefig(save_path+filename)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-forth",
   "metadata": {},
   "source": [
    "### Video comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "narrow-classroom",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d631f15bf244ba69e9a2ece37f1f4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=64, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d6db7cbc6a45aa8b7454ebf3e3d4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=64, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dafe8b2bdb481bbf167c1d7b258b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=64, min=1), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(frame)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_index = 0\n",
    "mode = \"test\"\n",
    "video_class = \"normal\"\n",
    "\n",
    "base_path = os.path.join(experiment_folder, \"outputs/samples/\")\n",
    "for t in [\"real\", \"fake\", \"substraction\"]:\n",
    "    path = os.path.join(base_path, t, mode, video_class)\n",
    "    video = sorted(os.listdir(path))[video_index]\n",
    "    data = \"video_{}\".format(t)\n",
    "    globals()[data] = []\n",
    "    for frame in sorted(os.listdir(os.path.join(path, video))):\n",
    "        globals()[data].append(cv2.cvtColor(\n",
    "            cv2.imread(\n",
    "                os.path.join(path, video, frame)\n",
    "            ), cv2.COLOR_BGR2RGB\n",
    "        ))\n",
    "    globals()[data] = np.r_[globals()[data]]  \n",
    "    \n",
    "assert video_real.shape[0] == video_fake.shape[0] == video_substraction.shape[0]\n",
    "\n",
    "widget = IntSlider(min=1, max=video_real.shape[0], step=1)\n",
    "\n",
    "interact(lambda frame: plt.imshow(video_real[frame-1]), frame=widget)\n",
    "interact(lambda frame: plt.imshow(video_fake[frame-1]), frame=widget)\n",
    "interact(lambda frame: plt.imshow(video_substraction[frame-1]), frame=widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
