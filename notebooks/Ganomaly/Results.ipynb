{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "endangered-assets",
   "metadata": {},
   "source": [
    "# GANomaly Notebook for Individual ExperimentResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-billy",
   "metadata": {},
   "source": [
    "## Initial Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-meter",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import dagostinoPearson_test, andersonDarling_test, shapiroWilks_test, chiSquare_test, fOneWay_test\n",
    "from utils.metrics import brownForsythe_test, levene_test, bartlett_test\n",
    "from utils.metrics import mannWhitney_test, kruskalWallis_test, kolmogorovSmirnov_test\n",
    "from utils.savers import generate_qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec12b3",
   "metadata": {},
   "source": [
    "### Experiment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"0002\"\n",
    "root_path = \"/home/jefelitman/Saved_Models/Anomaly_parkinson/\"\n",
    "for i in sorted(os.listdir(\"/home/jefelitman/Saved_Models/Anomaly_parkinson/\")):\n",
    "    if experiment_id in i:\n",
    "        experiment_folder = os.path.join(root_path, i)\n",
    "experiment_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-audit",
   "metadata": {},
   "source": [
    "## Quantitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-decline",
   "metadata": {},
   "source": [
    "### Metrics loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/train.csv\"))\n",
    "test_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/test.csv\"))\n",
    "print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "    train_metrics.loc[train_metrics.shape[0] - 1 ,\"gen_error\"],\n",
    "    train_metrics.loc[train_metrics.shape[0] - 1 ,\"disc_error\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"accuracy\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"precision\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"recall\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"specificity\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"f1_score\"],\n",
    "    test_metrics.loc[test_metrics.shape[0] - 1 ,\"auc\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-columbia",
   "metadata": {},
   "source": [
    "### Train Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "portions = epochs // 100\n",
    "columns = 5\n",
    "rows = (epochs // portions) // columns\n",
    "path = os.path.join(experiment_folder, \"outputs/graphics/quantitative/\")\n",
    "for metric in [\"gen_error\", \"disc_error\", \"accuracy\", \"specificity\"]:\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(30, 25))\n",
    "    fig.suptitle('{} over Epochs'.format(metric))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            axs[i, j].plot(train_metrics[metric][(i*columns+j)*portions:(i*columns+j+1)*portions])\n",
    "            filename = 'train_{}.png'.format(metric)\n",
    "    fig.savefig(path+filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-giant",
   "metadata": {},
   "source": [
    "### Test graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "portions = epochs // 100\n",
    "columns = 5\n",
    "rows = (epochs // portions) // columns\n",
    "path = os.path.join(experiment_folder, \"outputs/graphics/quantitative/\")\n",
    "for metric in test_metrics.columns[1:]:\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=(30, 25))\n",
    "    fig.suptitle('{} over Epochs'.format(metric))\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            axs[i, j].plot(test_metrics[metric][(i*columns+j)*portions:(i*columns+j+1)*portions])\n",
    "            filename = 'test_{}.png'.format(metric)\n",
    "    fig.savefig(path+filename)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-recipient",
   "metadata": {},
   "source": [
    "## Qualitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-handy",
   "metadata": {},
   "source": [
    "### Errors loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/errors/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "        for c in [\"normal\", \"abnormal\"]:\n",
    "            globals()[\"all_{}_{}\".format(t, c)] = np.r_[[]]\n",
    "            \n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for m in [\"train\", \"test\"]:\n",
    "        classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            all_data = \"all_{}_{}\".format(t, c)\n",
    "            errors = np.load(os.path.join(base_path, t, m, c+\".npy\"))\n",
    "            globals()[\"{}_{}_{}\".format(m, t, c)] = errors\n",
    "            globals()[all_data] = np.concatenate([globals()[all_data], errors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-remains",
   "metadata": {},
   "source": [
    "### Qualitative metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"train\", \"test\", \"all\"]:\n",
    "    print(\"-------------- {} ---------------------\".format(g))\n",
    "    classes = [\"normal\"] if g == \"train\" else [\"normal\", \"abnormal\"]\n",
    "    for c in classes:\n",
    "        for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "            data = globals()[\"{}_{}_{}\".format(g, t,c)]\n",
    "            m = np.mean(data)\n",
    "            s = np.std(data)\n",
    "            print(\"{} error ({}): {}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "                t,\n",
    "                c,\n",
    "                m,\n",
    "                s,\n",
    "                stats.skew(data),\n",
    "                stats.kurtosis(data),\n",
    "                int(m < 2*s),\n",
    "                1 - stats.norm(m, s).cdf(0)\n",
    "            ))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-status",
   "metadata": {},
   "source": [
    "### Normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"train\", \"test\", \"all\"]:\n",
    "    print(\"-------------- {} ---------------------\".format(g))\n",
    "    classes = [\"normal\"] if g == \"train\" else [\"normal\", \"abnormal\"]\n",
    "    for c in classes:\n",
    "        for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "            data = globals()[\"{}_{}_{}\".format(g, t,c)]\n",
    "            norm_dist = stats.norm.rvs(loc=np.mean(data), scale=np.std(data), size=data.shape, random_state=8128)\n",
    "            chi_test = chiSquare_test(data, norm_dist)\n",
    "            print(\"{} tests ({}): {}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "                t,\n",
    "                c,\n",
    "                int(brownForsythe_test(data, norm_dist)),\n",
    "                int(levene_test(data, norm_dist)),\n",
    "                int(bartlett_test(data, norm_dist)),\n",
    "                int(dagostinoPearson_test(data)),\n",
    "                int(andersonDarling_test(data)),\n",
    "                int(shapiroWilks_test(data)),\n",
    "                \"{} ({})\".format(int(chi_test[0]), round(chi_test[1], 5)),\n",
    "                int(fOneWay_test(data, norm_dist))\n",
    "            ))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1251327",
   "metadata": {},
   "source": [
    "### Grouping tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e646ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    print(\"-------------- {} ---------------------\".format(t))\n",
    "    for g1, g2 in [(\"train\", \"test\"), (\"test\", \"all\"), (\"train\", \"all\")]:\n",
    "        data1 = globals()[\"{}_{}_normal\".format(g1, t)]\n",
    "        data2 = globals()[\"{}_{}_normal\".format(g2, t)]\n",
    "        #norm_dist = stats.norm.rvs(loc=np.mean(data), scale=np.std(data), size=data.shape, random_state=8128)\n",
    "        print(\"{} vs {}: {}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            g1,\n",
    "            g2,\n",
    "            int(brownForsythe_test(data1, data2)),\n",
    "            int(levene_test(data1, data2)),\n",
    "            int(bartlett_test(data1, data2)),\n",
    "            int(mannWhitney_test(data1, data2)),\n",
    "            int(kruskalWallis_test(data1, data2)),\n",
    "            int(kolmogorovSmirnov_test(data1, data2)),\n",
    "            int(fOneWay_test(data1, data2))\n",
    "        ))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ccf7f5",
   "metadata": {},
   "source": [
    "### Classing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [\"test\", \"all\"]:\n",
    "    print(\"-------------- {} ---------------------\".format(g))\n",
    "    for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "        data1 = globals()[\"{}_{}_normal\".format(g, t)]\n",
    "        data2 = globals()[\"{}_{}_abnormal\".format(g, t)]\n",
    "        line = \"{} normal vs abnormal: {}\\t{}\\t{}\".format(\n",
    "            t,\n",
    "            int(brownForsythe_test(data1, data2)),\n",
    "            int(levene_test(data1, data2)),\n",
    "            int(bartlett_test(data1, data2)),\n",
    "        )\n",
    "        if g == \"test\":\n",
    "            line += \"\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "                int(mannWhitney_test(data1, data2)),\n",
    "                int(kruskalWallis_test(data1, data2)),\n",
    "                int(kolmogorovSmirnov_test(data1, data2)),\n",
    "                int(fOneWay_test(data1, data2))\n",
    "            )\n",
    "        else:\n",
    "            chi_1_test = chiSquare_test(data1, data2)\n",
    "            chi_2_test = chiSquare_test(data2, data1)\n",
    "            line += \"\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "                \"{} ({})\".format(int(chi_1_test[0]), round(chi_1_test[1], 5)),\n",
    "                \"{} ({})\".format(int(chi_2_test[0]), round(chi_2_test[1], 5)),\n",
    "                int(mannWhitney_test(data1, data2)),\n",
    "                int(kruskalWallis_test(data1, data2)),\n",
    "                int(kolmogorovSmirnov_test(data1, data2)),\n",
    "                int(fOneWay_test(data1, data2))\n",
    "            )\n",
    "        print(line)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-processor",
   "metadata": {},
   "source": [
    "### Train graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-merchandise",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\"]:\n",
    "        data = globals()[\"train_{}_{}\".format(t,c)]\n",
    "        generate_qq_plot(\n",
    "            data, \n",
    "            save_path, \n",
    "            \"train_{}_{}\".format(t,c),\n",
    "            \".png\",\n",
    "            np.mean(data),\n",
    "            np.std(data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-satin",
   "metadata": {},
   "source": [
    "### Test graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-panic",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-lease",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(15, 10))\n",
    "for i, t in enumerate([\"encoder\", \"contextual\", \"adversarial\"]):\n",
    "    data = \"test_{}_\".format(t)\n",
    "    axs[i].boxplot([globals()[data+\"normal\"], globals()[data+\"abnormal\"]], labels=['Normal', 'Abnormal'])\n",
    "    axs[i].set_title(\"{} errors\".format(t))\n",
    "\n",
    "filename = 'test_boxplot.png'\n",
    "fig.savefig(save_path+filename)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-multimedia",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        data = globals()[\"test_{}_{}\".format(t,c)]\n",
    "        generate_qq_plot(\n",
    "            data, \n",
    "            save_path, \n",
    "            \"test_{}_{}\".format(t,c),\n",
    "            \".png\",\n",
    "            np.mean(data),\n",
    "            np.std(data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d353b8",
   "metadata": {},
   "source": [
    "### All data graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d922f",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed03976",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig, axs = plt.subplots(rows, columns, figsize=(15, 10))\n",
    "for i, t in enumerate([\"encoder\", \"contextual\", \"adversarial\"]):\n",
    "    data = \"all_{}_\".format(t)\n",
    "    axs[i].boxplot([globals()[data+\"normal\"], globals()[data+\"abnormal\"]], labels=['Normal', 'Abnormal'])\n",
    "    axs[i].set_title(\"{} errors\".format(t))\n",
    "\n",
    "filename = 'all_data_boxplot.png'\n",
    "fig.savefig(save_path+filename)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b27c9",
   "metadata": {},
   "source": [
    "#### QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/qualitative/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        data = globals()[\"all_{}_{}\".format(t,c)]\n",
    "        generate_qq_plot(\n",
    "            data, \n",
    "            save_path, \n",
    "            \"all_{}_{}\".format(t,c),\n",
    "            \".png\",\n",
    "            np.mean(data),\n",
    "            np.std(data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-hudson",
   "metadata": {},
   "source": [
    "## Visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7363f",
   "metadata": {},
   "source": [
    "### Loading latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/latent_vectors/\")\n",
    "for n in [\"generator\", \"discriminator\"]:\n",
    "    for t in [\"input\", \"output\"]:\n",
    "        for m in [\"train\", \"test\"]:\n",
    "            classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "            for c in classes:\n",
    "                all_data = \"all_{}_{}_{}\".format(n, t, c)\n",
    "                if all_data not in globals().keys():\n",
    "                    globals()[all_data] = []\n",
    "            \n",
    "                data = \"{}_{}_{}_{}\".format(m, n, t, c)\n",
    "                globals()[data] = []\n",
    "                path = os.path.join(base_path, t + \"_\" + n, m, c)\n",
    "                for file in sorted(os.listdir(path)):\n",
    "                    vector = np.load(os.path.join(path, file))\n",
    "                    globals()[data].append(vector)\n",
    "                    globals()[all_data].append(vector)\n",
    "                globals()[data] = np.r_[globals()[data]]\n",
    "for n in [\"generator\", \"discriminator\"]:\n",
    "    for t in [\"input\", \"output\"]:\n",
    "        for c in [\"normal\", \"abnormal\"]:\n",
    "            all_data = \"all_{}_{}_{}\".format(n, t, c)\n",
    "            globals()[all_data] = np.r_[globals()[all_data]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-volume",
   "metadata": {},
   "source": [
    "### UMAP latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/visuals/\")\n",
    "for n in [\"generator\", \"discriminator\"]:\n",
    "    for t in [\"input\", \"output\"]:\n",
    "        for m in [\"train\", \"test\", \"all\"]:\n",
    "            classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "            globals()[\"{}_mapped_{}_{}\".format(m, n, t)] = umap.UMAP(random_state = 8128).fit_transform(np.concatenate(\n",
    "                    [globals()[\"{}_{}_{}_{}\".format(m, n, t, c)] for c in classes], axis=0\n",
    "                )\n",
    "            )\n",
    "\n",
    "            divisor = globals()[\"{}_{}_{}_normal\".format(m, n, t)].shape[0]\n",
    "            plt.scatter(globals()[\"{}_mapped_{}_{}\".format(m, n, t)][:divisor,0],\n",
    "                globals()[\"{}_mapped_{}_{}\".format(m, n, t)][:divisor,1], color=\"blue\", s=5, label=\"Normal\"\n",
    "            )\n",
    "            if \"abnormal\" in classes:\n",
    "                plt.scatter(globals()[\"{}_mapped_{}_{}\".format(m, n, t)][divisor:,0],\n",
    "                    globals()[\"{}_mapped_{}_{}\".format(m, n, t)][divisor:,1], color=\"red\", s=5, label=\"Abnormal\"\n",
    "                )\n",
    "            plt.legend()\n",
    "            plt.title(\"UMAP for {} {} data in {}\".format(n, t, m))\n",
    "            filename = '{}_umap_{}_{}.png'.format(m, n, t)\n",
    "            plt.savefig(save_path+filename)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92da19b",
   "metadata": {},
   "source": [
    "### PCA latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71663a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(experiment_folder, \"outputs/graphics/visuals/\")\n",
    "for n in [\"generator\", \"discriminator\"]:\n",
    "    for t in [\"input\", \"output\"]:\n",
    "        for m in [\"train\", \"test\", \"all\"]:\n",
    "            classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "            globals()[\"{}_mapped_{}_{}\".format(m, n, t)] = PCA(n_components=2, random_state=8128).fit_transform(np.concatenate(\n",
    "                    [globals()[\"{}_{}_{}_{}\".format(m, n, t, c)] for c in classes], axis=0\n",
    "                )\n",
    "            )\n",
    "\n",
    "            divisor = globals()[\"{}_{}_{}_normal\".format(m, n, t)].shape[0]\n",
    "            plt.scatter(globals()[\"{}_mapped_{}_{}\".format(m, n, t)][:divisor,0],\n",
    "                globals()[\"{}_mapped_{}_{}\".format(m, n, t)][:divisor,1], color=\"blue\", s=5, label=\"Normal\"\n",
    "            )\n",
    "            if \"abnormal\" in classes:\n",
    "                plt.scatter(globals()[\"{}_mapped_{}_{}\".format(m, n, t)][divisor:,0],\n",
    "                    globals()[\"{}_mapped_{}_{}\".format(m, n, t)][divisor:,1], color=\"red\", s=5, label=\"Abnormal\"\n",
    "                )\n",
    "            plt.legend()\n",
    "            plt.title(\"PCA for {} {} data in {}\".format(n, t, m))\n",
    "            filename = '{}_pca_{}_{}.png'.format(m, n, t)\n",
    "            plt.savefig(save_path+filename)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-forth",
   "metadata": {},
   "source": [
    "### Video comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_videos(real_videos, fake_videos, substraction_videos):\n",
    "    assert len(real_videos) == len(fake_videos) == len(substraction_videos)\n",
    "    for i in range(len(real_videos)):\n",
    "        assert real_videos[i].shape == fake_videos[i].shape == substraction_videos[i].shape\n",
    "    \n",
    "    frame_slider = IntSlider(min=1, max=real_videos[0].shape[0], step=1)\n",
    "    volume_slider = IntSlider(min=1, max=len(real_videos), step=1)\n",
    "\n",
    "    def update_frame_max(*args):\n",
    "        frame_slider.max = real_videos[volume_slider.value].shape[0]\n",
    "    volume_slider.observe(update_frame_max, 'value')\n",
    "    \n",
    "    interact(lambda volume, frame: plt.imshow(real_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )\n",
    "    interact(lambda volume, frame: plt.imshow(fake_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )\n",
    "    interact(lambda volume, frame: plt.imshow(substraction_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-classroom",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/samples/\")\n",
    "for t in [\"real\", \"fake\", \"substraction\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        globals()[\"{}_{}_videos\".format(t, c)] = []\n",
    "\n",
    "for t in [\"real\", \"fake\", \"substraction\"]:\n",
    "    for m in [\"train\", \"test\"]:\n",
    "        classes = [\"normal\"] if m == \"train\" else [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            videos_path = os.path.join(base_path, t, m, c)\n",
    "            for video_folder in sorted(os.listdir(videos_path)):\n",
    "                video = []\n",
    "                video_path = os.path.join(videos_path, video_folder)\n",
    "                for frame in sorted(os.listdir(video_path)):\n",
    "                    video.append(cv2.cvtColor(\n",
    "                        cv2.imread(\n",
    "                            os.path.join(video_path, frame)\n",
    "                        ), cv2.COLOR_BGR2RGB\n",
    "                    ))\n",
    "                globals()[\"{}_{}_videos\".format(t, c)].append(np.r_[video])\n",
    "len(real_normal_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2954088",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = \"normal\"\n",
    "show_all_videos(\n",
    "    globals()[\"real_{}_videos\".format(videos)],\n",
    "    globals()[\"fake_{}_videos\".format(videos)],\n",
    "    globals()[\"substraction_{}_videos\".format(videos)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
