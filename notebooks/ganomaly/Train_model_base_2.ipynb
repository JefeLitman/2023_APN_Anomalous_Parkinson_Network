{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac2128e",
   "metadata": {},
   "source": [
    "# GANomaly Notebook Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4a0ac",
   "metadata": {},
   "source": [
    "## Initial Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889d5d9",
   "metadata": {},
   "source": [
    "### Selecting the device to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c2cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa809b",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335353bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbe4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dict_features import get_ganomaly\n",
    "from utils.metrics import get_true_positives, get_true_negatives, get_false_positives, get_false_negatives\n",
    "from utils.metrics import accuracy, precision, recall, specificity, f1_score, get_AUC, get_mean\n",
    "from utils.savers import save_latent_vectors\n",
    "\n",
    "from models.ganomaly.model import get_2D_models, get_3D_models\n",
    "from models.ganomaly.utils.losses import l1_loss, l2_loss, BCELoss, l1_loss_batch, l2_loss_batch\n",
    "from models.ganomaly.utils.processing import normalize_accros_channels, min_max_scaler, resize\n",
    "from models.ganomaly.utils.processing import get_center_of_volume, rgb_to_grayscale\n",
    "from models.ganomaly.utils.processing import move_frames_to_channels, add_video_id\n",
    "from models.ganomaly.utils.processing import repeat_and_identify_frames, oversampling_equidistant_full\n",
    "\n",
    "from models.ganomaly.utils.weights_init import reinit_model\n",
    "from models.ganomaly.utils.exp_docs import experiment_folder_path, get_metrics_path, get_outputs_path\n",
    "from models.ganomaly.utils.printers import print_metrics\n",
    "from models.ganomaly.utils.savers import save_errors, save_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5ee89",
   "metadata": {},
   "source": [
    "### GPU Memory Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4527ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") != '-1':\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f1f26",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458997f7",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cda8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parkinson': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'id': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'frames': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'height': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'width': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'channels': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " 'video': FixedLenFeature(shape=[], dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CPUS = 16\n",
    "dataset_path = \"/data/Datasets/Parkinson/Gait_Dataset/TF_Records/gait_v2/dataset_09-jun-2022.tfrecord\"\n",
    "encoding_dictionary = get_ganomaly()\n",
    "encoding_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633681df",
   "metadata": {},
   "source": [
    "### General extraction function for tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77048ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_bytes_to_dict(example_bytes, encoding_dictionary):\n",
    "    return tf.io.parse_single_example(example_bytes, encoding_dictionary)\n",
    "\n",
    "def extract_data_from_dict(example_dict):\n",
    "    f = example_dict[\"frames\"]\n",
    "    h = example_dict[\"height\"]\n",
    "    w = example_dict[\"width\"]\n",
    "    c = example_dict[\"channels\"]\n",
    "    raw_volume = tf.io.decode_raw(example_dict[\"video\"], tf.uint8)\n",
    "    volume = tf.reshape(raw_volume, [f,h,w,c])\n",
    "    return tf.cast(volume, dtype=tf.float32), example_dict[\"parkinson\"], example_dict[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ee038",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc07655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 21:08:22.524715: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-16 21:08:23.237756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8101 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:1c:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset element_spec=(TensorSpec(shape=(None, None, None, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = tf.data.TFRecordDataset(dataset_path)\n",
    "dict_data = raw_data.map(lambda x: from_bytes_to_dict(x, encoding_dictionary), N_CPUS)\n",
    "total_data = dict_data.map(extract_data_from_dict, N_CPUS)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7447b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information about the data\n",
      "Total videos:  240\n",
      "Min value of frames:  72\n",
      "Max value of frames:  387\n",
      "Mean value of frames:  144.6375\n",
      "Unique ids:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30]\n"
     ]
    }
   ],
   "source": [
    "shape_videos = []\n",
    "labels_videos = []\n",
    "patients_ids = []\n",
    "for x, y, z in total_data:\n",
    "    shape_videos.append(x.numpy().shape)\n",
    "    labels_videos.append(y.numpy())\n",
    "    patients_ids.append(z.numpy())\n",
    "shape_videos = np.r_[shape_videos]\n",
    "labels_videos = np.r_[labels_videos]\n",
    "patients_ids = np.r_[patients_ids]\n",
    "print(\"Data information about the data\")\n",
    "print(\"Total videos: \", shape_videos.shape[0])\n",
    "print(\"Min value of frames: \", np.min(shape_videos[:,0]))\n",
    "print(\"Max value of frames: \", np.max(shape_videos[:,0]))\n",
    "print(\"Mean value of frames: \", np.mean(shape_videos[:,0]))\n",
    "print(\"Unique ids: \", np.unique(patients_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72a0dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video clips label 0: 351\n",
      "Video clips label 1: 313\n"
     ]
    }
   ],
   "source": [
    "n_1s = 0 \n",
    "n_0s = 0 \n",
    "videos_4_pat = {i:0 for i in np.unique(patients_ids)}\n",
    "for i, forma in enumerate(shape_videos):\n",
    "    frames = 64 #np.min(shape_videos[:,0])\n",
    "    to_sum = np.ceil(forma[0] / frames).astype(np.int64)\n",
    "    videos_4_pat[patients_ids[i]] += to_sum\n",
    "    if labels_videos[i] == 0:\n",
    "        n_0s += to_sum\n",
    "    elif labels_videos[i] == 1:\n",
    "        n_1s += to_sum\n",
    "    else:\n",
    "        print(\"Hay una etiqueta desconocida:\", labels_videos[i])\n",
    "print(\"Video clips label 0:\", n_0s)\n",
    "print(\"Video clips label 1:\", n_1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07913b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       "  <CacheDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>],\n",
       " <ConcatenateDataset element_spec=(TensorSpec(shape=(64, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_class = 1\n",
    "abnormal_class = 0\n",
    "frames = 64\n",
    "\n",
    "normal_patients_ids = np.unique(patients_ids[labels_videos == normal_class])\n",
    "abnormal_patients_ids = np.unique(patients_ids[labels_videos == abnormal_class])\n",
    "\n",
    "normal_data = total_data.filter(lambda x,y,z: tf.equal(y, normal_class))\n",
    "abnormal_data = total_data.filter(lambda x,y,z: tf.equal(y, abnormal_class))\n",
    "\n",
    "normal_patients = []\n",
    "for i in normal_patients_ids:\n",
    "    normal_patients.append(normal_data.filter(\n",
    "            lambda x, y, z: tf.equal(z, i)\n",
    "        ).map(\n",
    "            lambda x, y, z: resize(x, y, [frames, frames], z), N_CPUS\n",
    "        ).flat_map(\n",
    "            lambda x, y, z: oversampling_equidistant_full(x, y, frames, z)\n",
    "        ).map(\n",
    "            lambda x, y, z: rgb_to_grayscale(x, y, False, z), N_CPUS\n",
    "        ).map(\n",
    "            lambda x, y, z: normalize_accros_channels(x, y, 0.5, 0.5, z), N_CPUS\n",
    "        ).map(\n",
    "            lambda x, y, z: min_max_scaler(x, y, -1., 1., z), N_CPUS\n",
    "#         ).map(\n",
    "#             move_frames_to_channels, N_CPUS\n",
    "        ).map(\n",
    "            repeat_and_identify_frames, N_CPUS\n",
    "        ).enumerate().map(\n",
    "            add_video_id, N_CPUS\n",
    "        ).unbatch().cache()\n",
    "    )\n",
    "    \n",
    "abnormal_patients = []\n",
    "for i in abnormal_patients_ids:\n",
    "    abnormal_patients.append(abnormal_data.filter(\n",
    "            lambda x, y, z: tf.equal(z, i)\n",
    "        ).map(\n",
    "            lambda x, y, z: resize(x, y, [frames, frames], z), N_CPUS\n",
    "        ).flat_map(\n",
    "            lambda x, y, z: oversampling_equidistant_full(x, y, frames, z)\n",
    "        ).map(\n",
    "            lambda x, y, z: rgb_to_grayscale(x, y, False, z), N_CPUS\n",
    "        ).map(\n",
    "            lambda x, y, z: normalize_accros_channels(x, y, 0.5, 0.5, z), N_CPUS\n",
    "        ).map(\n",
    "            lambda x, y, z: min_max_scaler(x, y, -1., 1., z), N_CPUS\n",
    "#         ).map(\n",
    "#             move_frames_to_channels, N_CPUS\n",
    "        ).map(\n",
    "            repeat_and_identify_frames, N_CPUS\n",
    "        ).enumerate().map(\n",
    "            add_video_id, N_CPUS\n",
    "        ).unbatch().cache()\n",
    "    )\n",
    "\n",
    "abnormal_data = abnormal_patients[0]\n",
    "for i in range(1, len(abnormal_patients)):\n",
    "    abnormal_data = abnormal_data.concatenate(abnormal_patients[i])\n",
    "normal_patients, abnormal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769782ec",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ca97c",
   "metadata": {},
   "source": [
    "### Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a23f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "isize = 64 # Input size of the data (image or volume)\n",
    "nz = 100 # Context vector size\n",
    "nc = 1 # Quantity of channels in the data\n",
    "ngf = 64 # Quantity of initial filters in the first convolution of the encoder\n",
    "extra_layers = 0 # Quantity of layer blocks to add before reduction\n",
    "w_gen = (1, 50, 1) # Tuple with 3 elements (w_adv, w_con, w_enc) to use in the error of generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5661bf4",
   "metadata": {},
   "source": [
    "### Experiment params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8a3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dimension = \"2D\" # Dimension of model to use in experiment\n",
    "batch_size = 16*64 # Size of the batch for the model\n",
    "epochs = 20000 # Quantity of epochs to do in the training\n",
    "beta_1 = 0.5 # Momentum of beta 1 in adam optimizer for generator and discriminator\n",
    "beta_2 = 0.999 # Momentum of beta 2 in adam optimizer for generator and discriminator\n",
    "lr = 0.0002 # Initial learning rate for adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5abd1df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Train and Inference Steps ###############################\n",
    "# %load '../../models/ganomaly/utils/steps.py'\n",
    "@tf.function\n",
    "def train_step(x_data, w_gen = (1, 50, 1)):\n",
    "    \"\"\"Function that make one train step for whole GANomaly model and returns the errors and \n",
    "    relevant output variables.\n",
    "    Dependencies:\n",
    "        gen_model: A variable instance (with this name) of the generator model to be trained. (Keras Model Instance).\n",
    "        gen_opt: A variable instance (with this name) of optimizer for generator model to apply the learning process (Keras Optimizers Instance).\n",
    "        disc_model: A variable instance (with this name) of the discriminator model to be trained. (Keras Model Instance).\n",
    "        disc_opt: A variable instance (with this name) of optimizer for discriminator model to apply the learning process (Keras Optimizers Instance).\n",
    "    Args:\n",
    "        x_data: A Tensor with the batched data to be given for the model in the step (Tensor Instance).\n",
    "        w_gen: An instance of tuple with 3 elements in the following order (w_adv, w_con, w_enc) to use in the error of generator (Tuple).\n",
    "    \"\"\"\n",
    "    assert len(w_gen) == 3\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        #Forward process of networks\n",
    "        fake, latent_i, latent_o = gen_model(x_data, training=True)\n",
    "        pred_real, feat_real = disc_model(x_data, training=True)\n",
    "        pred_fake, feat_fake = disc_model(fake, training=True)\n",
    "        #Losses compute for generator\n",
    "        err_g_adv = l2_loss(feat_fake, feat_real)\n",
    "        err_g_con = l1_loss(x_data, fake)\n",
    "        err_g_enc = l2_loss(latent_i, latent_o)\n",
    "        err_g = err_g_adv * w_gen[0] + err_g_con * w_gen[1] +  err_g_enc * w_gen[2]\n",
    "        #Losses compute for discriminator\n",
    "        err_d_real = BCELoss(tf.ones_like(pred_real), pred_real)\n",
    "        err_d_fake = BCELoss(tf.zeros_like(pred_fake), pred_fake)\n",
    "        err_d = (err_d_real + err_d_fake) * 0.5\n",
    "\n",
    "    gradients_g = gen_tape.gradient(err_g, gen_model.trainable_variables)\n",
    "    gradients_d = disc_tape.gradient(err_d, disc_model.trainable_variables)\n",
    "\n",
    "    gen_opt.apply_gradients(zip(gradients_g, gen_model.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(gradients_d, disc_model.trainable_variables))\n",
    "\n",
    "    return err_g, err_d, fake, latent_i, latent_o, feat_real, feat_fake\n",
    "\n",
    "@tf.function\n",
    "def test_step(x_data):\n",
    "    \"\"\"Function that make one inference step for whole GANomaly model and returns its outputs to evaluate them.\n",
    "    Dependencies:\n",
    "        gen_model: A variable instance (with this name) of the generator model to be trained. (Keras Model Instance).\n",
    "    Args:\n",
    "        x_data: A Tensor with the batched data to be given for the model in the step (Tensor Instance).\n",
    "    \"\"\"\n",
    "    fake, latent_i, latent_o = gen_model(x_data, training=False)\n",
    "    pred_real, feat_real = disc_model(x_data, training=False)\n",
    "    pred_fake, feat_fake = disc_model(fake, training=False)\n",
    "    return fake, latent_i, latent_o, feat_real, feat_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9be29c",
   "metadata": {},
   "source": [
    "### Model Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0979c85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9671 - Train Step: 16\n",
      "Generator error: 0.5946279168128967\n",
      "Discriminator error: 7.590443134307861\n",
      "Accuracy: 0.9622556567192078\n",
      "Precision: 1.0\n",
      "Recall: 0.9622556567192078\n",
      "Specificity: nan\n",
      "F1_Score: 0.9807648196087426\n",
      "AUC: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m feat_real\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m feat_fake\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, xyi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    252\u001b[0m     fake_images, latent_i, latent_o, feat_real, feat_fake \u001b[38;5;241m=\u001b[39m test_step(xyi[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    254\u001b[0m     anomaly_scores \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mpow(tf\u001b[38;5;241m.\u001b[39msqueeze(latent_i\u001b[38;5;241m-\u001b[39mlatent_o), \u001b[38;5;241m2\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:486\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    485\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py:755\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    751\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 755\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py:787\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    784\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_iterator_v2(\n\u001b[1;32m    785\u001b[0m           output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[1;32m    786\u001b[0m           output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0m   \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m   \u001b[38;5;66;03m# Delete the resource when this object is deleted\u001b[39;00m\n\u001b[1;32m    789\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_deleter \u001b[38;5;241m=\u001b[39m IteratorResourceDeleter(\n\u001b[1;32m    790\u001b[0m       handle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[1;32m    791\u001b[0m       deleter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py:3315\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3314\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3315\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3318\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfolds = 5\n",
    "seed = 8128\n",
    "\n",
    "# Data partition for train and test with kfold\n",
    "kf = KFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "for train_indexes, test_indexes in kf.split(normal_patients):\n",
    "    data = normal_patients[train_indexes[0]]\n",
    "    total_samples = videos_4_pat[normal_patients_ids[train_indexes[0]]]\n",
    "    for i in range(1, len(train_indexes)):\n",
    "        data = data.concatenate(normal_patients[train_indexes[i]])\n",
    "        total_samples += videos_4_pat[normal_patients_ids[train_indexes[i]]]\n",
    "    train_folds.append(data.shuffle(total_samples*isize, reshuffle_each_iteration=True).batch(batch_size).prefetch(-1))\n",
    "        \n",
    "    data = normal_patients[test_indexes[0]]\n",
    "    total_samples = videos_4_pat[normal_patients_ids[test_indexes[0]]]\n",
    "    for i in range(1, len(test_indexes)):\n",
    "        data = data.concatenate(normal_patients[test_indexes[i]])\n",
    "        total_samples += videos_4_pat[normal_patients_ids[test_indexes[i]]]\n",
    "    data = data.concatenate(abnormal_data)\n",
    "    for i in abnormal_patients_ids:\n",
    "        total_samples += videos_4_pat[i]\n",
    "    test_folds.append(data.shuffle(total_samples*isize, reshuffle_each_iteration=True).batch(batch_size).prefetch(-1))\n",
    "\n",
    "for k in range(kfolds):\n",
    "    ######################### Replicability configuration ###############################\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    ######################### Experiment documentation ###############################\n",
    "    experiment_path, experiment_id = experiment_folder_path(\"/home/jefelitman/Saved_Models/Anomaly_parkinson/\", model_dimension, isize, nc)\n",
    "\n",
    "    # Metrics folder for model graphs\n",
    "    metric_save_path = get_metrics_path(experiment_path)\n",
    "\n",
    "    # Output folder for outputs\n",
    "    outputs_path = get_outputs_path(experiment_path)\n",
    "    experiment_path, metric_save_path, outputs_path\n",
    "    \n",
    "    with open(os.path.join(experiment_path, \"README.txt\"), \"w+\") as readme:\n",
    "        readme.write(\n",
    "\"\"\"This file contains information about the experiment made in this instance.\n",
    "\n",
    "All models saved don't include the optimizer, but this file explains how to train in the same conditions.\n",
    "\n",
    "Basic notation:\n",
    "\n",
    "- {i}_Ganomaly_{d}: Experiment id, name of the model and operation dimensionality of convolutions.\n",
    "- H x W x F, F x H x W x C or H x W x C: Data dimensions used where F are frames, H height, W width and C channels.\n",
    "\n",
    "Experiment settings:\n",
    "- The seed used was {seed} for python random module, numpy random and tf random after the library importations.\n",
    "- The batch size was of {batch}.\n",
    "- The optimizer used in this experiment was Adam for generator and discriminator.\n",
    "- The number of classes in this dataset are 2 (Normal and Parkinson) .\n",
    "- This experiment use the data of gait_v2/dataset_09-jun-2022 tfrecord.\n",
    "- The initial lr was of {lr}.\n",
    "- The beta 1 and beta 2 for adam optimizer was {beta_1} and {beta_2} respectively.\n",
    "- The total epochs made in this experiment was of {epochs}.\n",
    "- The context vector size (nz) was of {nz}.\n",
    "- The # channels in data (nc) was of {nc}.\n",
    "- The initial filters in the first convolution of the encoder was {ngf}.\n",
    "- The quantity of layer blocks to add before reduction was of {extra_layers}.\n",
    "- The weights for adversarial, contextual and encoder error respectively in generator were {w_gen}.\n",
    "\n",
    "Transformations applied to data (following this order):\n",
    "- Resize: We resize the frames of volumes to H x W ({size} x {size}).\n",
    "- Equidistant Oversampling volume: We take {size} frames sampled equidistant of volumes to train and test the data.\n",
    "- Convert: We convert the videos in RGB to Grayscale.\n",
    "- Normalize: We normalize the volume with mean and std of 0.5 for both.\n",
    "- Scale: We scale the data between -1 and 1 using min max scaler to be comparable with generated images.\n",
    "- Repeat: We repeat the label and identify each frame of the video to mantain their order.\n",
    "- Identify: We identify each video per patient with an integer value.\n",
    "- Randomize: We randomize the order of samples in every epoch.\n",
    "\n",
    "Training process:\n",
    "- The data doesn't have train and test partition but we make the partitions like this:\n",
    "    * ~80% (11 patients) of normal (parkinson) data is used in train for kfold {k}.\n",
    "    * ~20% (3 patients) of normal (parkinson) data is used in test for kfold {k}.\n",
    "    * 100% of abnormal (healthy) data are used in test.\n",
    "\"\"\".format(\n",
    "        i = experiment_id,\n",
    "        d = model_dimension,\n",
    "        seed = seed,\n",
    "        batch = batch_size,\n",
    "        lr = lr,\n",
    "        beta_1 = beta_1,\n",
    "        beta_2 = beta_2,\n",
    "        epochs = epochs,\n",
    "        nz = nz,\n",
    "        nc = nc,\n",
    "        ngf = ngf,\n",
    "        extra_layers = extra_layers,\n",
    "        w_gen = w_gen,\n",
    "        size = isize,\n",
    "        k = k + 1\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    ######################### Models creation ###############################\n",
    "    gen_model, disc_model = globals()[\"get_{}_models\".format(\n",
    "        model_dimension\n",
    "    )](isize, nz, nc, ngf, extra_layers)\n",
    "    \n",
    "    ######################### Optimizers creation ###############################\n",
    "    gen_opt = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "    disc_opt = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "    \n",
    "    ######################### Metrics Creation ###############################\n",
    "    TP = get_true_positives()\n",
    "    TN = get_true_negatives()\n",
    "    FP = get_false_positives()\n",
    "    FN = get_false_negatives()\n",
    "    gen_loss = get_mean()\n",
    "    disc_loss = get_mean()\n",
    "    AUC = get_AUC()\n",
    "\n",
    "    train_metrics_csv = open(os.path.join(metric_save_path,\"train.csv\"), \"w+\")\n",
    "    train_metrics_csv.write(\"epoch,gen_error,disc_error,accuracy,precision,recall,specificity,f1_score,auc\\n\")\n",
    "\n",
    "    test_metrics_csv = open(os.path.join(metric_save_path,\"test.csv\"), \"w+\")\n",
    "    test_metrics_csv.write(\"epoch,accuracy,precision,recall,specificity,f1_score,auc\\n\")\n",
    "    \n",
    "    train_data = train_folds[k]\n",
    "    test_data = test_folds[k]\n",
    "    \n",
    "    ######################### Loop Process ###############################\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Save the models every 500 epochs\n",
    "        if epoch % 1000 == 0 or epoch + 1 == epochs:\n",
    "            for i in sorted(os.listdir(experiment_path)):\n",
    "                if \"gen_model\" in i:\n",
    "                    os.remove(os.path.join(experiment_path, i))\n",
    "                elif \"disc_model\" in i:\n",
    "                    os.remove(os.path.join(experiment_path, i))\n",
    "            gen_model.save(os.path.join(experiment_path,\"gen_model_{}.h5\".format(epoch+1)), \n",
    "                include_optimizer=False, save_format='h5')\n",
    "            disc_model.save(os.path.join(experiment_path,\"disc_model_{}.h5\".format(epoch+1)), \n",
    "                include_optimizer=False, save_format='h5')\n",
    "            \n",
    "            # Delete the previous saved data\n",
    "            for path in outputs_path:\n",
    "                os.system(\"rm -rf {}\".format(os.path.join(path, \"*\")))\n",
    "\n",
    "        for step, xyi in enumerate(train_data):\n",
    "            err_g, err_d, fake_images, latent_i, latent_o, feat_real, feat_fake = train_step(xyi[0], w_gen)\n",
    "\n",
    "            if err_d < 1e-5 or tf.abs(err_d - disc_loss.result().numpy()) < 1e-5:\n",
    "                reinit_model(disc_model)\n",
    "\n",
    "            anomaly_scores = tf.math.reduce_mean(tf.math.pow(tf.squeeze(latent_i-latent_o), 2), axis=1)\n",
    "            anomaly_scores = (anomaly_scores - tf.reduce_min(anomaly_scores)) / (\n",
    "                tf.reduce_max(anomaly_scores) - tf.reduce_min(anomaly_scores)\n",
    "            )\n",
    "            if normal_class == 1:\n",
    "                anomaly_scores = 1 - anomaly_scores\n",
    "\n",
    "            TP.update_state(xyi[1], anomaly_scores)\n",
    "            TN.update_state(xyi[1], anomaly_scores)\n",
    "            FP.update_state(xyi[1], anomaly_scores)\n",
    "            FN.update_state(xyi[1], anomaly_scores)\n",
    "            AUC.update_state(xyi[1], anomaly_scores)\n",
    "            gen_loss.update_state(err_g)\n",
    "            disc_loss.update_state(err_d)\n",
    "            acc = accuracy(TP.result().numpy(), TN.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "            pre = precision(TP.result().numpy(), FP.result().numpy())\n",
    "            rec = recall(TP.result().numpy(), FN.result().numpy())\n",
    "            spe = specificity(TN.result().numpy(), FP.result().numpy())\n",
    "            f1 = f1_score(TP.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "            auc = AUC.result().numpy()\n",
    "            gen_error = gen_loss.result().numpy()\n",
    "            disc_error = disc_loss.result().numpy()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print_metrics(epoch, step, acc, pre, rec, spe, f1, auc, err_g, err_d)\n",
    "\n",
    "            # Save the latent vectors, videos and errors in the last epoch and every 500 epochs\n",
    "            if epoch + 1 == epochs or epoch % 1000 == 0:\n",
    "                save_latent_vectors(tf.squeeze(latent_i).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[0], True)\n",
    "                save_latent_vectors(tf.squeeze(latent_o).numpy(), xyi[1].numpy(), xyi[2].numpy(),  outputs_path[1], True)\n",
    "                save_latent_vectors(tf.reshape(feat_real, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[2], True)\n",
    "                save_latent_vectors(tf.reshape(feat_fake, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(),  outputs_path[3], True)\n",
    "\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in xyi[0]]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[4],\n",
    "                    True\n",
    "                )\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in fake_images]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[5],\n",
    "                    True\n",
    "                )\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in tf.abs(xyi[0] - fake_images)]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[6],\n",
    "                    True\n",
    "                )\n",
    "\n",
    "                save_errors(l2_loss_batch(feat_real, feat_fake), xyi[1].numpy(), outputs_path[7], True)\n",
    "                save_errors(l1_loss_batch(xyi[0], fake_images), xyi[1].numpy(), outputs_path[8], True)\n",
    "                save_errors(l2_loss_batch(latent_i, latent_o), xyi[1].numpy(), outputs_path[9], True)\n",
    "\n",
    "        # Save train metrics\n",
    "        train_metrics_csv.write(\"{e},{loss_g},{loss_d},{acc},{pre},{rec},{spe},{f1},{auc}\\n\".format(\n",
    "            e = epoch,\n",
    "            loss_g = gen_error,\n",
    "            loss_d = disc_error,\n",
    "            acc = acc,\n",
    "            pre = pre,\n",
    "            rec = rec,\n",
    "            spe = spe,\n",
    "            f1 = f1,\n",
    "            auc = auc\n",
    "        ))\n",
    "        TP.reset_states()\n",
    "        TN.reset_states()\n",
    "        FP.reset_states()\n",
    "        FN.reset_states()\n",
    "        AUC.reset_states()\n",
    "        gen_loss.reset_states()\n",
    "        disc_loss.reset_states()\n",
    "        \n",
    "        del xyi\n",
    "        del err_g\n",
    "        del err_d\n",
    "        del fake_images\n",
    "        del latent_i\n",
    "        del latent_o\n",
    "        del feat_real\n",
    "        del feat_fake\n",
    "\n",
    "        for step, xyi in enumerate(test_data):\n",
    "            fake_images, latent_i, latent_o, feat_real, feat_fake = test_step(xyi[0])\n",
    "\n",
    "            anomaly_scores = tf.math.reduce_mean(tf.math.pow(tf.squeeze(latent_i-latent_o), 2), axis=1)\n",
    "            anomaly_scores = (anomaly_scores - tf.reduce_min(anomaly_scores)) / (\n",
    "                tf.reduce_max(anomaly_scores) - tf.reduce_min(anomaly_scores)\n",
    "            )\n",
    "            if normal_class == 1:\n",
    "                anomaly_scores = 1 - anomaly_scores\n",
    "\n",
    "            TP.update_state(xyi[1], anomaly_scores)\n",
    "            TN.update_state(xyi[1], anomaly_scores)\n",
    "            FP.update_state(xyi[1], anomaly_scores)\n",
    "            FN.update_state(xyi[1], anomaly_scores)\n",
    "            AUC.update_state(xyi[1], anomaly_scores)\n",
    "            acc = accuracy(TP.result().numpy(), TN.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "            pre = precision(TP.result().numpy(), FP.result().numpy())\n",
    "            rec = recall(TP.result().numpy(), FN.result().numpy())\n",
    "            spe = specificity(TN.result().numpy(), FP.result().numpy())\n",
    "            f1 = f1_score(TP.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "            auc = AUC.result().numpy()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print_metrics(epoch, step, acc, pre, rec, spe, f1, auc)\n",
    "\n",
    "            # Save the latent vectors, videos and errors in the last epoch and every 500 epochs\n",
    "            if epoch + 1 == epochs or epoch % 1000 == 0:\n",
    "                save_latent_vectors(tf.squeeze(latent_i).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[0], False)\n",
    "                save_latent_vectors(tf.squeeze(latent_o).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[1], False)\n",
    "                save_latent_vectors(tf.reshape(feat_real, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[2], False)\n",
    "                save_latent_vectors(tf.reshape(feat_fake, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[3], False)\n",
    "\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in xyi[0]]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[4],\n",
    "                    False\n",
    "                )\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in fake_images]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[5],\n",
    "                    False\n",
    "                )\n",
    "                batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in tf.abs(xyi[0] - fake_images)]]\n",
    "                save_frames(\n",
    "                    batch_frames, \n",
    "                    xyi[1].numpy(), \n",
    "                    xyi[2].numpy(), \n",
    "                    xyi[4].numpy(), \n",
    "                    xyi[3].numpy(), \n",
    "                    outputs_path[6],\n",
    "                    False\n",
    "                )\n",
    "\n",
    "                save_errors(l2_loss_batch(feat_real, feat_fake), xyi[1].numpy(), outputs_path[7], False)\n",
    "                save_errors(l1_loss_batch(xyi[0], fake_images), xyi[1].numpy(), outputs_path[8], False)\n",
    "                save_errors(l2_loss_batch(latent_i, latent_o), xyi[1].numpy(), outputs_path[9], False)\n",
    "\n",
    "        # Save test metrics\n",
    "        test_metrics_csv.write(\"{e},{acc},{pre},{rec},{spe},{f1},{auc}\\n\".format(\n",
    "            e = epoch,\n",
    "            acc = acc,\n",
    "            pre = pre,\n",
    "            rec = rec,\n",
    "            spe = spe,\n",
    "            f1 = f1,\n",
    "            auc = auc\n",
    "        ))\n",
    "        TP.reset_states()\n",
    "        TN.reset_states()\n",
    "        FP.reset_states()\n",
    "        FN.reset_states()\n",
    "        AUC.reset_states()\n",
    "\n",
    "    train_metrics_csv.close()\n",
    "    test_metrics_csv.close()\n",
    "    \n",
    "    ######################### Save final models ###############################\n",
    "    for i in sorted(os.listdir(experiment_path)):\n",
    "        if \"gen_model\" in i:\n",
    "            os.remove(os.path.join(experiment_path, i))\n",
    "        elif \"disc_model\" in i:\n",
    "            os.remove(os.path.join(experiment_path, i))\n",
    "    gen_model.save(os.path.join(experiment_path,\"gen_model.h5\"), include_optimizer=False, save_format='h5')\n",
    "    disc_model.save(os.path.join(experiment_path,\"disc_model.h5\"), include_optimizer=False, save_format='h5')\n",
    "    \n",
    "    ######################### Deleting the used model ###############################\n",
    "    del gen_model\n",
    "    del disc_model\n",
    "    del train_data\n",
    "    del test_data\n",
    "    del gen_opt\n",
    "    del disc_opt\n",
    "    del xyi\n",
    "    del fake_images\n",
    "    del latent_i\n",
    "    del latent_o\n",
    "    del feat_real\n",
    "    del feat_fake\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "# Empezo a correr el 24-May-2022 a las 11:36\n",
    "# Termino el 27-May-2022 a las 11:39`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a15bf",
   "metadata": {},
   "source": [
    "### Replicability configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8128\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78291fd2",
   "metadata": {},
   "source": [
    "### Experiment documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path, experiment_id = experiment_folder_path(\"/home/jefelitman/Saved_Models/Anomaly_parkinson/\", model_dimension, isize, nc)\n",
    "\n",
    "# Metrics folder for model graphs\n",
    "metric_save_path = get_metrics_path(experiment_path)\n",
    "\n",
    "# Output folder for outputs\n",
    "outputs_path = get_outputs_path(experiment_path)\n",
    "experiment_path, metric_save_path, outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = open(os.path.join(experiment_path, \"README.txt\"), \"w+\")\n",
    "readme.write(\n",
    "\"\"\"This file contains information about the experiment made in this instance.\n",
    "\n",
    "All models saved don't include the optimizer, but this file explains how to train in the same conditions.\n",
    "\n",
    "Basic notation:\n",
    "\n",
    "- {i}_Ganomaly_{d}: Experiment id, name of the model and operation dimensionality of convolutions.\n",
    "- H x W x F or F x H x W x C: Data dimensions used where F are frames, H height, W width and C channels.\n",
    "\n",
    "Experiment settings:\n",
    "- The seed used was {seed} for python random module, numpy random and tf random after the library importations.\n",
    "- The batch size was of {batch}.\n",
    "- The optimizer used in this experiment was Adam for generator and discriminator.\n",
    "- The number of classes in this dataset are 2 (Normal and Parkinson) .\n",
    "- This experiment use the data of parkinson_2020_cutted tfrecord.\n",
    "- The initial lr was of {lr}.\n",
    "- The beta 1 and beta 2 for adam optimizer was {beta_1} and {beta_2} respectively.\n",
    "- The total epochs made in this experiment was of {epochs}.\n",
    "- The context vector size (nz) was of {nz}.\n",
    "- The # channels in data (nc) was of {nc}.\n",
    "- The initial filters in the first convolution of the encoder was {ngf}.\n",
    "- The quantity of layer blocks to add before reduction was of {extra_layers}.\n",
    "- The weights for adversarial, contextual and encoder error respectively in generator were {w_gen}.\n",
    "\n",
    "Transformations applied to data (following this order):\n",
    "- Resize: We resize the frames of volumes to H x W (64 x 64).\n",
    "- Centered volume: We take 64 frames on the center of volume to train and test the data.\n",
    "- Convert: We convert the videos in RGB to Grayscale.\n",
    "- Normalize: We normalize the volume with mean and std of 0.5 for both.\n",
    "- Scale: We scale the data between -1 and 1 using min max scaler to be comparable with generated images.\n",
    "- Repeat: We repeat the label and identify each frame of the video to conserver the order.\n",
    "- Identify: We identify each video per patient with an integer value.\n",
    "- Randomize: We randomize the order of samples in every epoch.\n",
    "\n",
    "Training process:\n",
    "- The data doesn't have train and test partition but we make the partitions like this:\n",
    "    * 81.8% (72 videos/9 patients) of normal (healthy) data is used in train randomly selected.\n",
    "    * 29.2% (16 videos/2 patients) of normal (healthy) data is used in test randomly selected.\n",
    "    * 100% of abnormal (parkinson) data are used in test.\n",
    "\"\"\".format(\n",
    "        i = experiment_id,\n",
    "        d = model_dimension,\n",
    "        seed = seed,\n",
    "        batch = batch_size,\n",
    "        lr = lr,\n",
    "        beta_1 = beta_1,\n",
    "        beta_2 = beta_2,\n",
    "        epochs = epochs,\n",
    "        nz = nz,\n",
    "        nc = nc,\n",
    "        ngf = ngf,\n",
    "        extra_layers = extra_layers,\n",
    "        w_gen = w_gen\n",
    "    )\n",
    ")\n",
    "readme.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07db5b5",
   "metadata": {},
   "source": [
    "### Models creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df3b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_model, disc_model = globals()[\"get_{}_models\".format(\n",
    "    model_dimension\n",
    ")](isize, nz, nc, ngf, extra_layers)\n",
    "gen_model.summary()\n",
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88399a8",
   "metadata": {},
   "source": [
    "### Optimizers creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08902fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "disc_opt = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "gen_opt, disc_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dabd1b",
   "metadata": {},
   "source": [
    "### Train and Inference steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea989b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load '../../models/ganomaly/utils/steps.py'\n",
    "@tf.function\n",
    "def train_step(x_data, w_gen = (1, 50, 1)):\n",
    "    \"\"\"Function that make one train step for whole GANomaly model and returns the errors and \n",
    "    relevant output variables.\n",
    "    Dependencies:\n",
    "        gen_model: A variable instance (with this name) of the generator model to be trained. (Keras Model Instance).\n",
    "        gen_opt: A variable instance (with this name) of optimizer for generator model to apply the learning process (Keras Optimizers Instance).\n",
    "        disc_model: A variable instance (with this name) of the discriminator model to be trained. (Keras Model Instance).\n",
    "        disc_opt: A variable instance (with this name) of optimizer for discriminator model to apply the learning process (Keras Optimizers Instance).\n",
    "    Args:\n",
    "        x_data: A Tensor with the batched data to be given for the model in the step (Tensor Instance).\n",
    "        w_gen: An instance of tuple with 3 elements in the following order (w_adv, w_con, w_enc) to use in the error of generator (Tuple).\n",
    "    \"\"\"\n",
    "    assert len(w_gen) == 3\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        #Forward process of networks\n",
    "        fake, latent_i, latent_o = gen_model(x_data, training=True)\n",
    "        pred_real, feat_real = disc_model(x_data, training=True)\n",
    "        pred_fake, feat_fake = disc_model(fake, training=True)\n",
    "        #Losses compute for generator\n",
    "        err_g_adv = l2_loss(feat_fake, feat_real)\n",
    "        err_g_con = l1_loss(x_data, fake)\n",
    "        err_g_enc = l2_loss(latent_i, latent_o)\n",
    "        err_g = err_g_adv * w_gen[0] + err_g_con * w_gen[1] +  err_g_enc * w_gen[2]\n",
    "        #Losses compute for discriminator\n",
    "        err_d_real = BCELoss(tf.ones_like(pred_real), pred_real)\n",
    "        err_d_fake = BCELoss(tf.zeros_like(pred_fake), pred_fake)\n",
    "        err_d = (err_d_real + err_d_fake) * 0.5\n",
    "\n",
    "    gradients_g = gen_tape.gradient(err_g, gen_model.trainable_variables)\n",
    "    gradients_d = disc_tape.gradient(err_d, disc_model.trainable_variables)\n",
    "\n",
    "    gen_opt.apply_gradients(zip(gradients_g, gen_model.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(gradients_d, disc_model.trainable_variables))\n",
    "\n",
    "    return err_g, err_d, fake, latent_i, latent_o, feat_real, feat_fake\n",
    "\n",
    "@tf.function\n",
    "def test_step(x_data):\n",
    "    \"\"\"Function that make one inference step for whole GANomaly model and returns its outputs to evaluate them.\n",
    "    Dependencies:\n",
    "        gen_model: A variable instance (with this name) of the generator model to be trained. (Keras Model Instance).\n",
    "    Args:\n",
    "        x_data: A Tensor with the batched data to be given for the model in the step (Tensor Instance).\n",
    "    \"\"\"\n",
    "    fake, latent_i, latent_o = gen_model(x_data, training=False)\n",
    "    pred_real, feat_real = disc_model(x_data, training=False)\n",
    "    pred_fake, feat_fake = disc_model(fake, training=False)\n",
    "    return fake, latent_i, latent_o, feat_real, feat_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dff4c2",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b2d06",
   "metadata": {},
   "source": [
    "### Metrics creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = get_true_positives()\n",
    "TN = get_true_negatives()\n",
    "FP = get_false_positives()\n",
    "FN = get_false_negatives()\n",
    "gen_loss = get_mean()\n",
    "disc_loss = get_mean()\n",
    "AUC = get_AUC()\n",
    "\n",
    "train_metrics_csv = open(os.path.join(metric_save_path,\"train.csv\"), \"w+\")\n",
    "train_metrics_csv.write(\"epoch,gen_error,disc_error,accuracy,precision,recall,specificity,f1_score,auc\\n\")\n",
    "\n",
    "test_metrics_csv = open(os.path.join(metric_save_path,\"test.csv\"), \"w+\")\n",
    "test_metrics_csv.write(\"epoch,accuracy,precision,recall,specificity,f1_score,auc\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab5136",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793cb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Data partition for train and test\n",
    "    partition_point = len(normal_patients) - 2\n",
    "    np.random.shuffle(normal_patients)\n",
    "    train_data = normal_patients[0]\n",
    "    for i in range(1, partition_point):\n",
    "        train_data = train_data.concatenate(normal_patients[i])\n",
    "    train_data = train_data.shuffle(72*64, reshuffle_each_iteration=True).batch(batch_size).prefetch(-1)\n",
    "    \n",
    "    test_data = normal_patients[partition_point]\n",
    "    for i in range(partition_point + 1, len(normal_patients)):\n",
    "        test_data = test_data.concatenate(normal_patients[i])\n",
    "    test_data = test_data.concatenate(abnormal_data)\n",
    "    test_data = test_data.shuffle((88+16)*64, reshuffle_each_iteration=True).batch(batch_size).prefetch(-1)\n",
    "    \n",
    "    # Save the models every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        for i in sorted(os.listdir(experiment_path)):\n",
    "            if \"gen_model\" in i:\n",
    "                os.remove(os.path.join(experiment_path, i))\n",
    "            elif \"disc_model\" in i:\n",
    "                os.remove(os.path.join(experiment_path, i))\n",
    "        gen_model.save(os.path.join(experiment_path,\"gen_model_{}.h5\".format(epoch+1)), \n",
    "            include_optimizer=False, save_format='h5')\n",
    "        disc_model.save(os.path.join(experiment_path,\"disc_model_{}.h5\".format(epoch+1)), \n",
    "            include_optimizer=False, save_format='h5')\n",
    "    \n",
    "    for step, xyi in enumerate(train_data):\n",
    "        err_g, err_d, fake_images, latent_i, latent_o, feat_real, feat_fake = train_step(xyi[0])\n",
    "        \n",
    "        if err_d < 1e-5 or tf.abs(err_d - disc_loss.result().numpy()) < 1e-5:\n",
    "            reinit_model(disc_model)\n",
    "            \n",
    "        anomaly_scores = tf.math.reduce_mean(tf.math.pow(tf.squeeze(latent_i-latent_o), 2), axis=1)\n",
    "        anomaly_scores = (anomaly_scores - tf.reduce_min(anomaly_scores)) / (\n",
    "            tf.reduce_max(anomaly_scores) - tf.reduce_min(anomaly_scores)\n",
    "        )\n",
    "            \n",
    "        TP.update_state(xyi[1], anomaly_scores)\n",
    "        TN.update_state(xyi[1], anomaly_scores)\n",
    "        FP.update_state(xyi[1], anomaly_scores)\n",
    "        FN.update_state(xyi[1], anomaly_scores)\n",
    "        AUC.update_state(xyi[1], anomaly_scores)\n",
    "        gen_loss.update_state(err_g)\n",
    "        disc_loss.update_state(err_d)\n",
    "        acc = accuracy(TP.result().numpy(), TN.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "        pre = precision(TP.result().numpy(), FP.result().numpy())\n",
    "        rec = recall(TP.result().numpy(), FN.result().numpy())\n",
    "        spe = specificity(TN.result().numpy(), FP.result().numpy())\n",
    "        f1 = f1_score(TP.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "        auc = AUC.result().numpy()\n",
    "        gen_error = gen_loss.result().numpy()\n",
    "        disc_error = disc_loss.result().numpy()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print_metrics(epoch, step, acc, pre, rec, spe, f1, auc, err_g, err_d)\n",
    "        \n",
    "        # Save the latent vectors, videos and errors in the last epoch\n",
    "        if epoch + 1 == epochs:\n",
    "            save_latent_vectors(tf.squeeze(latent_i).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[0], True)\n",
    "            save_latent_vectors(tf.squeeze(latent_o).numpy(), xyi[1].numpy(), xyi[2].numpy(),  outputs_path[1], True)\n",
    "            save_latent_vectors(tf.reshape(feat_real, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[2], True)\n",
    "            save_latent_vectors(tf.reshape(feat_fake, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(),  outputs_path[3], True)\n",
    "            \n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in xyi[0]]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[4],\n",
    "                True\n",
    "            )\n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in fake_images]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[5],\n",
    "                True\n",
    "            )\n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in tf.abs(xyi[0] - fake_images)]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[6],\n",
    "                True\n",
    "            )\n",
    "            \n",
    "            save_errors(l2_loss_batch(feat_real, feat_fake), xyi[1].numpy(), outputs_path[7], True)\n",
    "            save_errors(l1_loss_batch(xyi[0], fake_images), xyi[1].numpy(), outputs_path[8], True)\n",
    "            save_errors(l2_loss_batch(latent_i, latent_o), xyi[1].numpy(), outputs_path[9], True)\n",
    "        \n",
    "    # Save train metrics\n",
    "    train_metrics_csv.write(\"{e},{loss_g},{loss_d},{acc},{pre},{rec},{spe},{f1},{auc}\\n\".format(\n",
    "        e = epoch,\n",
    "        loss_g = gen_error,\n",
    "        loss_d = disc_error,\n",
    "        acc = acc,\n",
    "        pre = pre,\n",
    "        rec = rec,\n",
    "        spe = spe,\n",
    "        f1 = f1,\n",
    "        auc = auc\n",
    "    ))\n",
    "    TP.reset_states()\n",
    "    TN.reset_states()\n",
    "    FP.reset_states()\n",
    "    FN.reset_states()\n",
    "    AUC.reset_states()\n",
    "    gen_loss.reset_states()\n",
    "    disc_loss.reset_states()\n",
    "    \n",
    "    for step, xyi in enumerate(test_data):\n",
    "        fake_images, latent_i, latent_o, feat_real, feat_fake = test_step(xyi[0])\n",
    "        \n",
    "        anomaly_scores = tf.math.reduce_mean(tf.math.pow(tf.squeeze(latent_i-latent_o), 2), axis=1)\n",
    "        anomaly_scores = (anomaly_scores - tf.reduce_min(anomaly_scores)) / (\n",
    "            tf.reduce_max(anomaly_scores) - tf.reduce_min(anomaly_scores)\n",
    "        )\n",
    "            \n",
    "        TP.update_state(xyi[1], anomaly_scores)\n",
    "        TN.update_state(xyi[1], anomaly_scores)\n",
    "        FP.update_state(xyi[1], anomaly_scores)\n",
    "        FN.update_state(xyi[1], anomaly_scores)\n",
    "        AUC.update_state(xyi[1], anomaly_scores)\n",
    "        acc = accuracy(TP.result().numpy(), TN.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "        pre = precision(TP.result().numpy(), FP.result().numpy())\n",
    "        rec = recall(TP.result().numpy(), FN.result().numpy())\n",
    "        spe = specificity(TN.result().numpy(), FP.result().numpy())\n",
    "        f1 = f1_score(TP.result().numpy(), FP.result().numpy(), FN.result().numpy())\n",
    "        auc = AUC.result().numpy()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print_metrics(epoch, step, acc, pre, rec, spe, f1, auc)\n",
    "        \n",
    "        # Save the latent vectors, videos and errors in the last epoch\n",
    "        if epoch + 1 == epochs:\n",
    "            save_latent_vectors(tf.squeeze(latent_i).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[0], False)\n",
    "            save_latent_vectors(tf.squeeze(latent_o).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[1], False)\n",
    "            save_latent_vectors(tf.reshape(feat_real, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[2], False)\n",
    "            save_latent_vectors(tf.reshape(feat_fake, [xyi[0].shape[0], -1]).numpy(), xyi[1].numpy(), xyi[2].numpy(), outputs_path[3], False)\n",
    "            \n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in xyi[0]]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[4],\n",
    "                False\n",
    "            )\n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in fake_images]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[5],\n",
    "                False\n",
    "            )\n",
    "            batch_frames = np.r_[[min_max_scaler(i, 0, 0, 255, 0)[0].numpy() for i in tf.abs(xyi[0] - fake_images)]]\n",
    "            save_frames(\n",
    "                batch_frames, \n",
    "                xyi[1].numpy(), \n",
    "                xyi[2].numpy(), \n",
    "                xyi[4].numpy(), \n",
    "                xyi[3].numpy(), \n",
    "                outputs_path[6],\n",
    "                False\n",
    "            )\n",
    "            \n",
    "            save_errors(l2_loss_batch(feat_real, feat_fake), xyi[1].numpy(), outputs_path[7], False)\n",
    "            save_errors(l1_loss_batch(xyi[0], fake_images), xyi[1].numpy(), outputs_path[8], False)\n",
    "            save_errors(l2_loss_batch(latent_i, latent_o), xyi[1].numpy(), outputs_path[9], False)\n",
    "        \n",
    "    # Save test metrics\n",
    "    test_metrics_csv.write(\"{e},{acc},{pre},{rec},{spe},{f1},{auc}\\n\".format(\n",
    "        e = epoch,\n",
    "        acc = acc,\n",
    "        pre = pre,\n",
    "        rec = rec,\n",
    "        spe = spe,\n",
    "        f1 = f1,\n",
    "        auc = auc\n",
    "    ))\n",
    "    TP.reset_states()\n",
    "    TN.reset_states()\n",
    "    FP.reset_states()\n",
    "    FN.reset_states()\n",
    "    AUC.reset_states()\n",
    "    \n",
    "train_metrics_csv.close()\n",
    "test_metrics_csv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6aabff",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(os.listdir(experiment_path)):\n",
    "    if \"gen_model\" in i:\n",
    "        os.remove(os.path.join(experiment_path, i))\n",
    "    elif \"disc_model\" in i:\n",
    "        os.remove(os.path.join(experiment_path, i))\n",
    "gen_model.save(os.path.join(experiment_path,\"gen_model.h5\"), include_optimizer=False, save_format='h5')\n",
    "disc_model.save(os.path.join(experiment_path,\"disc_model.h5\"), include_optimizer=False, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac497284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMpezo a correr el 03-Mar-2022 a las 09:00\n",
    "# Termino el 11-Mar-2022 a las 21:00"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
