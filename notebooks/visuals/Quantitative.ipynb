{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9b3551",
   "metadata": {},
   "source": [
    "# Notebook for generate Quantitative Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c661af1",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15818400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 22:25:18.145914: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a659e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import format_index\n",
    "from utils.metrics import brownForsythe_test, levene_test, bartlett_test\n",
    "from utils.metrics import accuracy, precision, recall, specificity, f1_score\n",
    "from utils.metrics import mannWhitney_test, kruskalWallis_test, kolmogorovSmirnov_test\n",
    "from utils.metrics import dagostinoPearson_test, andersonDarling_test, shapiroWilks_test, chiSquare_test, fOneWay_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61171d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_curve(y_true, y_pred, num_thresholds=200):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    thresholds = np.linspace(np.min(y_pred), np.max(y_pred), num_thresholds)\n",
    "    for t in thresholds:\n",
    "        tp = np.count_nonzero(np.logical_and(y_true, (y_pred > t)))\n",
    "        fp = np.count_nonzero(np.logical_and(np.logical_not(y_true), (y_pred > t)))\n",
    "        fn = np.count_nonzero(np.logical_and(y_true, (y_pred <= t)))\n",
    "        if tp+fp == 0:\n",
    "            precisions.append(0)\n",
    "        else:\n",
    "            precisions.append(precision(tp, fp))\n",
    "        if tp + fn == 0:\n",
    "            recalls.append(0)\n",
    "        else:\n",
    "            recalls.append(recall(tp, fn))\n",
    "    return np.r_[precisions], np.r_[recalls], thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105e5c1",
   "metadata": {},
   "source": [
    "### Experiment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c458d4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/Ganomaly_3D/0006_Ganomaly3D-64x64x64x1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id = \"0006\"\n",
    "root_path = \"../../results/Ganomaly_3D/\"\n",
    "for i in sorted(os.listdir(root_path)):\n",
    "    if experiment_id in i:\n",
    "        experiment_folder = os.path.join(root_path, i)\n",
    "experiment_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c97bf",
   "metadata": {},
   "source": [
    "### Errors loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9813fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/errors/\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "        for c in [\"normal\", \"abnormal\"]:\n",
    "            globals()[\"all_{}_{}\".format(t, c)] = np.r_[[]]\n",
    "\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for m in [\"train\", \"val\", \"test\"]:\n",
    "        if m == \"train\":\n",
    "            if os.path.isfile(os.path.join(base_path, t, m, \"normal.npy\")):\n",
    "                classes = [\"normal\"] \n",
    "            else:\n",
    "                classes = [\"abnormal\"]\n",
    "        else:\n",
    "            classes = [\"normal\", \"abnormal\"]\n",
    "\n",
    "        for c in classes:\n",
    "            all_data = \"all_{}_{}\".format(t, c)\n",
    "            errors = np.load(os.path.join(base_path, t, m, c + \".npy\"))\n",
    "            globals()[\"{}_{}_{}\".format(m, t, c)] = errors\n",
    "            globals()[all_data] = np.concatenate([globals()[all_data], errors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a328b2",
   "metadata": {},
   "source": [
    "### Errors by patients loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b046b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/latent_vectors/input_generator\")\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for m in [\"train\", \"val\", \"test\"]:\n",
    "        if m == \"train\":\n",
    "            if \"train_encoder_normal\" in globals().keys():\n",
    "                classes = [\"normal\"] \n",
    "            else:\n",
    "                classes = [\"abnormal\"]\n",
    "        else:\n",
    "            classes = [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            patients_ids_positions = [\n",
    "                int(i.split(\"_\")[1].split(\"-\")[1].split(\".\")[0]) for i in sorted(\n",
    "                    os.listdir(os.path.join(base_path, m, c))\n",
    "                )\n",
    "            ]\n",
    "            data = \"{}_{}_{}\".format(m, t, c)\n",
    "            key = \"{}_{}\".format(data, \"patients\")\n",
    "            globals()[key] = {}\n",
    "\n",
    "            for p_id in np.unique(patients_ids_positions):\n",
    "                globals()[key][p_id] = []\n",
    "\n",
    "            for i, p_id in enumerate(patients_ids_positions):\n",
    "                globals()[key][p_id].append(globals()[data][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11817d9",
   "metadata": {},
   "source": [
    "### Precision vs Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb910f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\"normal\", \"abnormal\"]\n",
    "for group in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    data = \"val_{}_\".format(group)\n",
    "    y_true = np.concatenate([[i]*globals()[data + j].shape[0] for i,j in enumerate(errors)]) \n",
    "    y_pred = np.concatenate([globals()[data+i] for i in errors])\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    deltas_pre_4_rec = np.abs(precisions - recalls)\n",
    "    threshold = thresholds[np.argmin(deltas_pre_4_rec[deltas_pre_4_rec != 0])]\n",
    "\n",
    "    path = os.path.join(experiment_folder, \"outputs/graphics/quantitative/\")\n",
    "    plt.plot(thresholds, precisions, label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls, label=\"Recall\")\n",
    "    plt.axvline(threshold, color=\"black\", alpha=0.5)\n",
    "    plt.title('Precision and Recall for different thresholds in Validation of {} error'.format(group))\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Precision/Recall')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path, \"Precision_vs_Recall_{}.png\".format(group)),dpi=1200)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
