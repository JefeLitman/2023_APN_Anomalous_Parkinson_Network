{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9b3551",
   "metadata": {},
   "source": [
    "# Notebook to generate PCA Graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c661af1",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15818400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ac20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_videos(real_videos, fake_videos, substraction_videos):\n",
    "    assert len(real_videos) == len(fake_videos) == len(substraction_videos)\n",
    "    for i in range(len(real_videos)):\n",
    "        assert real_videos[i].shape == fake_videos[i].shape == substraction_videos[i].shape\n",
    "    \n",
    "    frame_slider = IntSlider(min=1, max=real_videos[0].shape[0], step=1)\n",
    "    volume_slider = IntSlider(min=1, max=len(real_videos), step=1)\n",
    "\n",
    "    def update_frame_max(*args):\n",
    "        frame_slider.max = real_videos[volume_slider.value].shape[0]\n",
    "    volume_slider.observe(update_frame_max, 'value')\n",
    "    \n",
    "    interact(lambda volume, frame: plt.imshow(real_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )\n",
    "    interact(lambda volume, frame: plt.imshow(fake_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )\n",
    "    interact(lambda volume, frame: plt.imshow(substraction_videos[volume-1][frame-1]),\n",
    "        volume=volume_slider, frame=frame_slider\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105e5c1",
   "metadata": {},
   "source": [
    "### Experiment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = \"0006\"\n",
    "root_path = \"../../results/Ganomaly_3D/\"\n",
    "for i in sorted(os.listdir(root_path)):\n",
    "    if experiment_id in i:\n",
    "        experiment_folder = os.path.join(root_path, i)\n",
    "experiment_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c97bf",
   "metadata": {},
   "source": [
    "### Reconstructions Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9813fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(experiment_folder, \"outputs/samples/\")\n",
    "for t in [\"real\", \"fake\", \"substraction\"]:\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        globals()[\"{}_{}_videos\".format(t, c)] = []\n",
    "\n",
    "for t in [\"real\", \"fake\", \"substraction\"]:\n",
    "    for m in [\"train\", \"val\", \"test\"]:\n",
    "        if m == \"train\":\n",
    "            if len(os.listdir(os.path.join(base_path, t, m, \"normal\"))) != 0:\n",
    "                classes = [\"normal\"] \n",
    "            else:\n",
    "                classes = [\"abnormal\"]\n",
    "        else:\n",
    "            classes = [\"normal\", \"abnormal\"]\n",
    "        for c in classes:\n",
    "            videos_path = os.path.join(base_path, t, m, c)\n",
    "            for video_folder in sorted(os.listdir(videos_path)):\n",
    "                video = []\n",
    "                video_path = os.path.join(videos_path, video_folder)\n",
    "                for frame in sorted(os.listdir(video_path)):\n",
    "                    video.append(cv2.cvtColor(\n",
    "                        cv2.imread(\n",
    "                            os.path.join(video_path, frame)\n",
    "                        ), cv2.COLOR_BGR2RGB\n",
    "                    ))\n",
    "                globals()[\"{}_{}_videos\".format(t, c)].append(np.r_[video])\n",
    "len(real_normal_videos), len(real_abnormal_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ecd0d",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25290d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = \"normal\"\n",
    "show_all_videos(\n",
    "    globals()[\"real_{}_videos\".format(videos)],\n",
    "    globals()[\"fake_{}_videos\".format(videos)],\n",
    "    globals()[\"substraction_{}_videos\".format(videos)],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
