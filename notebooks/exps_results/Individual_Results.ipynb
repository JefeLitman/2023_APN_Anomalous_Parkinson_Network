{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "endangered-assets",
   "metadata": {},
   "source": [
    "# Notebook for Individual Experiment Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-meter",
   "metadata": {},
   "source": [
    "### Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 03:44:24.993986: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bored-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import repeat_vector_to_size\n",
    "from utils.metrics import precision_recall_curve, tpr_fpr_curve, all_metrics_curve\n",
    "from utils.metrics import homocedasticity_level, shapeness_level\n",
    "from utils.metrics import accuracy, precision, recall, specificity, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec12b3",
   "metadata": {},
   "source": [
    "### Experiment selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5551c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/Ganomaly_3D/0012_train_healthy/0013_Ganomaly3D-64x64x64x1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 8128\n",
    "np.random.seed(seed)\n",
    "experiment_id = \"0013\"\n",
    "root_path = \"../../results/Ganomaly_3D/0012_train_healthy/\"\n",
    "for i in sorted(os.listdir(root_path)):\n",
    "    if experiment_id in i:\n",
    "        experiment_folder = os.path.join(root_path, i)\n",
    "experiment_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-audit",
   "metadata": {},
   "source": [
    "### Quantitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-handy",
   "metadata": {},
   "source": [
    "##### Errors loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "configured-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_path = os.path.join(experiment_folder, \"outputs/errors\")\n",
    "vectors_path = os.path.join(experiment_folder, \"outputs/latent_vectors/input_generator\")\n",
    "\n",
    "# Initializing dict for losses of different elements in network\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    data = \"{}_losses\".format(t)\n",
    "    globals()[data] = {}\n",
    "    for c in [\"normal\", \"abnormal\"]:\n",
    "        globals()[data][c] = {}\n",
    "        for m in [\"train\", \"val\", \"test\"]:\n",
    "            globals()[data][c][m] = {}\n",
    "\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for m in [\"train\", \"val\", \"test\"]:\n",
    "        if m == \"train\":\n",
    "            if os.path.isfile(os.path.join(errors_path, t, m, \"normal.npy\")):\n",
    "                classes = [\"normal\"] \n",
    "            else:\n",
    "                classes = [\"abnormal\"]\n",
    "        else:\n",
    "            classes = [\"normal\", \"abnormal\"]\n",
    "\n",
    "        for c in classes:\n",
    "            error_file = os.path.join(errors_path, t, m, c + \".npy\")\n",
    "            if os.path.isfile(error_file):\n",
    "                data = \"{}_losses\".format(t)\n",
    "                errors = np.load(error_file)\n",
    "                patients_ids_positions = [\n",
    "                    int(i.split(\"_\")[1].split(\"-\")[1]) for i in sorted(\n",
    "                        os.listdir(os.path.join(vectors_path, m, c))\n",
    "                    )\n",
    "                ]\n",
    "                assert len(errors) == len(patients_ids_positions)\n",
    "                for p_id in np.unique(patients_ids_positions):\n",
    "                    globals()[data][c][m][p_id] = []\n",
    "                    \n",
    "                for i, p_id in enumerate(patients_ids_positions):\n",
    "                    globals()[data][c][m][p_id].append(errors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "abbebbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>max</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mean</th>\n",
       "      <th>coverage</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mean+2std</th>\n",
       "      <th>coverage</th>\n",
       "      <th>mean+var</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>2.515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.553</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.172</td>\n",
       "      <td>1.471</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.725</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1.475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.522</td>\n",
       "      <td>1.911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    max  coverage   mean  coverage    std    var  median  \\\n",
       "0           9  0.232       1.0  0.182     0.500  0.027  0.001   0.182   \n",
       "1          25  2.515       1.0  1.553     0.550  0.415  0.172   1.471   \n",
       "2          30  1.475       1.0  0.885     0.522  0.342  0.117   0.882   \n",
       "\n",
       "   coverage  mean+2std  coverage  mean+var  coverage  \n",
       "0     0.500      0.265       1.0     0.183     0.500  \n",
       "1     0.500      2.797       1.0     1.725     0.625  \n",
       "2     0.522      1.911       1.0     1.002     0.609  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stats(p_id, data):\n",
    "    data_np = np.r_[data]\n",
    "    n = len(data)\n",
    "    data_max = np.max(data)\n",
    "    coverage_max = np.count_nonzero(data_np <= data_max) / n\n",
    "    mean = np.mean(data)\n",
    "    coverage_mean = np.count_nonzero(data_np <= mean) / n\n",
    "    std = np.std(data)\n",
    "    var = np.var(data)\n",
    "    median = np.median(data)\n",
    "    coverage_median = np.count_nonzero(data_np <= median) / n\n",
    "    m2s = mean + 3*std\n",
    "    coverage_m2s = np.count_nonzero(data_np <= m2s) / n\n",
    "    mv = mean + var\n",
    "    coverage_mv = np.count_nonzero(data_np <= mv) / n\n",
    "    return [\n",
    "        p_id,\n",
    "        round(data_max, 3),\n",
    "        round(coverage_max, 3),\n",
    "        round(mean, 3),\n",
    "        round(coverage_mean, 3),\n",
    "        round(std, 3),\n",
    "        round(var, 3),\n",
    "        round(median, 3),\n",
    "        round(coverage_median, 3),\n",
    "        round(m2s, 3),\n",
    "        round(coverage_m2s, 3),\n",
    "        round(mv, 3),\n",
    "        round(coverage_mv, 3)\n",
    "    ]\n",
    "    \n",
    "samples = encoder_losses[\"normal\"][\"val\"]\n",
    "table = []\n",
    "columns = [\"patient_id\",\"max\", \"coverage\",\"mean\", \"coverage\", \"std\", \"var\", \"median\", \"coverage\", \"mean+2std\", \"coverage\", \"mean+var\", \"coverage\"]\n",
    "for p_id in samples:\n",
    "    table.append(get_stats(p_id, samples[p_id]))\n",
    "pd.DataFrame(table, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "24aaf9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5595238095238095, 0.6190476190476191)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for c in [\"normal\", \"abnormal\"]:\n",
    "    parts = []\n",
    "    for g in [\"train\", \"val\", \"test\"]:\n",
    "        samples = encoder_losses[c][g]\n",
    "        for p_id in samples:\n",
    "            parts.append(np.r_[contextual_losses[c][g][p_id]])\n",
    "    data.append(parts)\n",
    "homocedasticity_level(*data), shapeness_level(*data, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-decline",
   "metadata": {},
   "source": [
    "##### Metrics loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "optimum-genetics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics\n",
      "AUC: 0.0\n",
      "Acc: 0.8559321761131287\n",
      "Pre: 0.0\n",
      "Rec: nan\n",
      "Spe: 0.8559321761131287\n",
      "F1: 0.0\n",
      "===============\n",
      "val metrics\n",
      "AUC: 0.6015672087669373\n",
      "Acc: 0.6478873491287231\n",
      "Pre: 0.7407407164573669\n",
      "Rec: 0.3174603283405304\n",
      "Spe: 0.9113923907279968\n",
      "F1: 0.4444444444444444\n",
      "===============\n",
      "test metrics\n",
      "AUC: 0.8472222685813904\n",
      "Acc: 0.5874999761581421\n",
      "Pre: 0.8666666746139526\n",
      "Rec: 0.2954545319080353\n",
      "Spe: 0.9444444179534912\n",
      "F1: 0.4406779661016949\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "train_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/train.csv\"))\n",
    "val_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/val.csv\"))\n",
    "test_metrics = pd.read_csv(os.path.join(experiment_folder, \"metrics/test.csv\"))\n",
    "for i in [\"train\", \"val\", \"test\"]:\n",
    "    metric_file = globals()[\"{}_metrics\".format(i)]\n",
    "    index = metric_file.shape[0] - 1\n",
    "    print(\"{} metrics\".format(i))\n",
    "    print(\"AUC: {}\".format(metric_file.loc[index, \"auc\"]))\n",
    "    print(\"Acc: {}\".format(metric_file.loc[index, \"accuracy\"]))\n",
    "    print(\"Pre: {}\".format(metric_file.loc[index, \"precision\"]))\n",
    "    print(\"Rec: {}\".format(metric_file.loc[index, \"recall\"]))\n",
    "    print(\"Spe: {}\".format(metric_file.loc[index, \"specificity\"]))\n",
    "    print(\"F1: {}\".format(metric_file.loc[index, \"f1_score\"]))\n",
    "    print(\"=\"*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d621ee",
   "metadata": {},
   "source": [
    "##### Selecting the threshold and calculating the standard metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9532a4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partition</th>\n",
       "      <th>Group</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Pre</th>\n",
       "      <th>Rec</th>\n",
       "      <th>Spe</th>\n",
       "      <th>F1</th>\n",
       "      <th>Homo</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val</td>\n",
       "      <td>encoder</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>encoder</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val</td>\n",
       "      <td>contextual</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.163</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>contextual</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>adversarial</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Partition        Group  AUC-ROC  Threshold    Acc    Pre  Rec    Spe     F1  \\\n",
       "0       val      encoder    0.222      0.265  0.667  0.600  1.0  0.333  0.750   \n",
       "1      test      encoder    0.250      0.265  0.500  0.500  1.0  0.000  0.667   \n",
       "2       val   contextual    0.667      0.163  1.000  1.000  1.0  1.000  1.000   \n",
       "3      test   contextual    0.500      0.163  0.750  0.667  1.0  0.500  0.800   \n",
       "4       val  adversarial    0.556      0.456  0.833  0.750  1.0  0.667  0.857   \n",
       "5      test  adversarial   -0.000      0.456  0.500  0.500  1.0  0.000  0.667   \n",
       "\n",
       "    Homo  Shape  \n",
       "0  0.452  0.681  \n",
       "1  0.452  0.681  \n",
       "2  0.560  0.619  \n",
       "3  0.560  0.619  \n",
       "4  0.531  0.676  \n",
       "5  0.531  0.676  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_table = []\n",
    "lambda_value = 3\n",
    "data_columns = [\"Partition\", \"Group\", \"AUC-ROC\", \"Threshold\", \"Acc\", \"Pre\", \"Rec\", \"Spe\", \"F1\", \"Homo\", \"Shape\"]\n",
    "\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for part in [\"val\", \"test\"]:\n",
    "        data = \"{}_losses\".format(t)\n",
    "        if len(globals()[data][\"normal\"][\"train\"]) != 0:\n",
    "            errors = [\"normal\", \"abnormal\"]\n",
    "        elif len(globals()[data][\"abnormal\"][\"train\"]) != 0:\n",
    "            errors = [\"abnormal\", \"normal\"]\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for ci, c in enumerate(errors):\n",
    "            samples = globals()[data][c][part]\n",
    "            y_pred += [\n",
    "                np.mean(samples[i]) + lambda_value*np.std(samples[i]) for i in samples\n",
    "            ]\n",
    "            y_true += [ci]*len(samples)\n",
    "        y_true = np.r_[y_true]\n",
    "        y_pred = np.r_[y_pred]\n",
    "        tpr, fpr, _ = tpr_fpr_curve(y_true, y_pred)\n",
    "\n",
    "        if part == \"val\":\n",
    "            accs, pres, recs, spes, f1s, thresholds = all_metrics_curve(y_true, y_pred)\n",
    "            table_metrics = np.concatenate([\n",
    "                accs.reshape([-1,1]), \n",
    "#                 pres.reshape([-1,1]), \n",
    "                recs.reshape([-1,1]), \n",
    "#                 spes.reshape([-1,1]), \n",
    "#                 f1s.reshape([-1,1])\n",
    "            ], axis=1)\n",
    "            threshold = thresholds[np.argmax(np.mean(table_metrics, axis=1))]\n",
    "            # deltas = np.abs(tpr - fpr)\n",
    "            # threshold = thresholds[np.argmin(deltas[deltas != 0])]\n",
    "    \n",
    "        #threshold = 1.174\n",
    "        y_pred = (y_pred > threshold).astype(np.int64)\n",
    "\n",
    "        TP = tf.keras.metrics.TruePositives()\n",
    "        TN = tf.keras.metrics.TrueNegatives()\n",
    "        FP = tf.keras.metrics.FalsePositives()\n",
    "        FN = tf.keras.metrics.FalseNegatives()\n",
    "\n",
    "        TP.update_state(y_true, y_pred)\n",
    "        TN.update_state(y_true, y_pred)\n",
    "        FP.update_state(y_true, y_pred)\n",
    "        FN.update_state(y_true, y_pred)\n",
    "        \n",
    "        classes_data = []\n",
    "        for c in [\"normal\", \"abnormal\"]:\n",
    "            parts = []\n",
    "            for g in [\"train\", \"val\", \"test\"]:\n",
    "                samples = globals()[data][c][g]\n",
    "                for p_id in samples:\n",
    "                    parts.append(np.r_[samples[p_id]])\n",
    "            classes_data.append(parts)\n",
    "\n",
    "\n",
    "        data_table.append([\n",
    "            part,\n",
    "            t,\n",
    "            round(auc(fpr, tpr), 3),\n",
    "            round(threshold, 3),\n",
    "            round(accuracy(TP.result().numpy(), TN.result().numpy(), FP.result().numpy(), FN.result().numpy()), 3),\n",
    "            round(precision(TP.result().numpy(), FP.result().numpy()), 3),\n",
    "            round(recall(TP.result().numpy(), FN.result().numpy()), 3),\n",
    "            round(specificity(TN.result().numpy(), FP.result().numpy()), 3),\n",
    "            round(f1_score(TP.result().numpy(), FP.result().numpy(), FN.result().numpy()), 3),\n",
    "            round(homocedasticity_level(*classes_data), 3),\n",
    "            round(shapeness_level(*classes_data, seed=seed), 3)\n",
    "        ])\n",
    "pd.DataFrame(data_table, columns=data_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-recipient",
   "metadata": {},
   "source": [
    "### Qualitative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-remains",
   "metadata": {},
   "source": [
    "##### Dist. Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = []\n",
    "data_columns = [\"Group\", \"Element\", \"Class\", \"Min\", \"Max\", \"Mean\", \"Std\", \"Ske\", \"Kur\", \"CDF(x > 0)\"]\n",
    "\n",
    "for g in [\"train\", \"val\", \"test\", \"all\"]:\n",
    "    if g == \"train\":\n",
    "        classes = [\"check\"]\n",
    "    else:\n",
    "        classes = [\"normal\", \"abnormal\"]\n",
    "    for cl in classes:\n",
    "        for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "            if cl == \"check\":\n",
    "                if \"train_{}_normal\".format(t) in globals().keys():\n",
    "                    c = \"normal\"\n",
    "                else:\n",
    "                    c = \"abnormal\"\n",
    "            else:\n",
    "                c = cl\n",
    "            data = globals()[\"{}_{}_{}\".format(g, t, c)]\n",
    "            m = np.mean(data)\n",
    "            s = np.std(data)\n",
    "            data_table.append([\n",
    "                g,\n",
    "                t,\n",
    "                c,\n",
    "                np.min(data),\n",
    "                np.max(data),\n",
    "                m,\n",
    "                s,\n",
    "                stats.skew(data),\n",
    "                stats.kurtosis(data),\n",
    "                1 - stats.norm(m, s).cdf(0)\n",
    "            ])\n",
    "pd.DataFrame(data_table, columns=data_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41352f71",
   "metadata": {},
   "source": [
    "##### Grouping tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e810c92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_table = []\n",
    "data_columns = [\"Element\", \"G1\", \"G2\", \"Brow\", \"Lev\", \"Chi2 G1 -> G2\", \"Chi2 G2 -> G1\"]\n",
    "\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for g1, g2 in [\n",
    "        (\"train\", \"val\"), (\"train\", \"test\"), (\"train\", \"all\"), \n",
    "        (\"val\", \"test\"), (\"val\", \"all\"),\n",
    "        (\"test\", \"all\")\n",
    "    ]:\n",
    "        if \"train_{}_normal\".format(t) in globals().keys():\n",
    "            c = \"normal\"\n",
    "        else:\n",
    "            c = \"abnormal\"\n",
    "        data1 = globals()[\"{}_{}_{}\".format(g1, t, c)]\n",
    "        data2 = globals()[\"{}_{}_{}\".format(g2, t, c)]\n",
    "        if data1.shape[0] > data2.shape[0]:\n",
    "            sub_data1 = np.r_[sorted(data1)]\n",
    "            sub_data2 = np.r_[sorted(repeat_vector_to_size(data2, data1.shape[0]))]\n",
    "        elif data1.shape[0] < data2.shape[0]:\n",
    "            sub_data1 = np.r_[sorted(repeat_vector_to_size(data1, data2.shape[0]))]\n",
    "            sub_data2 = np.r_[sorted(data2)]\n",
    "        else:\n",
    "            sub_data1 = data1\n",
    "            sub_data2 = data2\n",
    "        chi_test_g1 = chiSquare_test(sub_data1, sub_data2)\n",
    "        chi_test_g2 = chiSquare_test(sub_data2, sub_data1)\n",
    "        data_table.append([\n",
    "            t,\n",
    "            g1,\n",
    "            g2,\n",
    "            int(brownForsythe_test(data1, data2)),\n",
    "            int(levene_test(data1, data2)),\n",
    "            \"{} ({})\".format(int(chi_test_g1[0]), round(chi_test_g1[1], 5)),\n",
    "            \"{} ({})\".format(int(chi_test_g2[0]), round(chi_test_g2[1], 5)),\n",
    "        ])\n",
    "pd.DataFrame(data_table, columns=data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = []\n",
    "data_columns = [\"Element\", \"G1\", \"G2\", \"Brow\", \"Lev\", \"Chi2 G1 -> G2\", \"Chi2 G2 -> G1\"]\n",
    "\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for g1, g2 in [\n",
    "        (\"train\", \"val\"), (\"train\", \"test\"), #(\"train\", \"all\"), \n",
    "        (\"val\", \"test\"), #(\"val\", \"all\"),\n",
    "        #(\"test\", \"all\")\n",
    "    ]:\n",
    "        if \"train_{}_normal\".format(t) in globals().keys():\n",
    "            c = \"normal\"\n",
    "        else:\n",
    "            c = \"abnormal\"\n",
    "        data1 = globals()[\"{}_{}_{}\".format(g1, t, c)]\n",
    "        data2 = globals()[\"{}_{}_{}\".format(g2, t, \"abnormal\")]\n",
    "        if data1.shape[0] > data2.shape[0]:\n",
    "            sub_data1 = np.r_[sorted(data1)]\n",
    "            sub_data2 = np.r_[sorted(repeat_vector_to_size(data2, data1.shape[0]))]\n",
    "        elif data1.shape[0] < data2.shape[0]:\n",
    "            sub_data1 = np.r_[sorted(repeat_vector_to_size(data1, data2.shape[0]))]\n",
    "            sub_data2 = np.r_[sorted(data2)]\n",
    "        else:\n",
    "            sub_data1 = data1\n",
    "            sub_data2 = data2\n",
    "        chi_test_g1 = chiSquare_test(sub_data1, sub_data2)\n",
    "        chi_test_g2 = chiSquare_test(sub_data2, sub_data1)\n",
    "        data_table.append([\n",
    "            t,\n",
    "            g1,\n",
    "            g2,\n",
    "            int(brownForsythe_test(data1, data2)),\n",
    "            int(levene_test(data1, data2)),\n",
    "            \"{} ({})\".format(int(chi_test_g1[0]), round(chi_test_g1[1], 5)),\n",
    "            \"{} ({})\".format(int(chi_test_g2[0]), round(chi_test_g2[1], 5)),\n",
    "        ])\n",
    "pd.DataFrame(data_table, columns=data_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991a650",
   "metadata": {},
   "source": [
    "### Classing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = []\n",
    "data_columns = [\"Group\", \"Element\", \"Brow\", \"Lev\", \"Chi2 N -> A\", \"Chi2 A -> N\"]\n",
    "for t in [\"encoder\", \"contextual\", \"adversarial\"]:\n",
    "    for g1 in [\"train\", \"val\", \"test\", \"all\"]:\n",
    "        for g2 in [\"val\", \"test\", \"all\"]:\n",
    "            if \"train_{}_normal\".format(t) in globals().keys():\n",
    "                data1 = globals()[\"{}_{}_normal\".format(g1, t)]\n",
    "                data2 = globals()[\"{}_{}_abnormal\".format(g2, t)]\n",
    "            else:\n",
    "                data2 = globals()[\"{}_{}_abnormal\".format(g1, t)]\n",
    "                data1 = globals()[\"{}_{}_normal\".format(g2, t)]\n",
    "            if data1.shape[0] > data2.shape[0]:\n",
    "                sub_data1 = np.r_[sorted(data1)]\n",
    "                sub_data2 = np.r_[sorted(repeat_vector_to_size(data2, data1.shape[0]))]\n",
    "            elif data1.shape[0] < data2.shape[0]:\n",
    "                sub_data1 = np.r_[sorted(repeat_vector_to_size(data1, data2.shape[0]))]\n",
    "                sub_data2 = np.r_[sorted(data2)]\n",
    "            else:\n",
    "                sub_data1 = np.r_[sorted(data1)]\n",
    "                sub_data2 = np.r_[sorted(data2)]\n",
    "            chi_test_1 = chiSquare_test(sub_data1, sub_data2)\n",
    "            chi_test_2 = chiSquare_test(sub_data2, sub_data1)\n",
    "            data_table.append([\n",
    "                \"{} vs {}\".format(g1, g2),\n",
    "                t, \n",
    "                int(brownForsythe_test(data1, data2)),\n",
    "                int(levene_test(data1, data2)),\n",
    "                \"{} ({})\".format(int(chi_test_1[0]), round(chi_test_1[1], 5)),\n",
    "                \"{} ({})\".format(int(chi_test_2[0]), round(chi_test_2[1], 5))\n",
    "            ])\n",
    "pd.DataFrame(data_table, columns=data_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
